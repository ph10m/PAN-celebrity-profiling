{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True  # if pickle models are saved or not!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "read_multiple = False\n",
    "if read_multiple:\n",
    "    import glob\n",
    "    samples = glob.glob(os.path.join(os.getcwd(), 'SPLIT') + '/*')\n",
    "    dfs = []\n",
    "    for sample in samples:\n",
    "        print(sample)\n",
    "        df = pd.read_csv(sample, names = ['id', 'text', 'birthyear', 'fame', 'gender', 'occupation'])\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    del dfs\n",
    "    df.reset_index()\n",
    "    df.to_csv('all_data_cleaned.csv')\n",
    "elif not load:  # skip if the pickled files are present\n",
    "    df = pd.read_csv('all_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df:\n",
    "    df = df.sample(frac=1)  # shuffle it!\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load:\n",
    "    with open('pickles/years.pickle', 'rb') as handle:\n",
    "        birthyear_labels = pickle.load(handle)\n",
    "else:\n",
    "    # squish the birthyears to a scale from 0->1\n",
    "    birthyears = df.birthyear.unique()\n",
    "    _min = min(birthyears)\n",
    "    _max = max(birthyears)\n",
    "\n",
    "    def normalize_birthyear(year):\n",
    "        return (year-_min)/(_max-_min)\n",
    "\n",
    "    birthyear_labels = df.birthyear.apply(normalize_birthyear)\n",
    "    birthyear_labels = birthyear_labels.values\n",
    "\n",
    "    with open('pickles/years.pickle', 'wb') as handle:\n",
    "        pickle.dump(birthyear_labels, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load:\n",
    "    with open('pickles/labels.pickle', 'rb') as handle:\n",
    "        labels = pickle.load(handle)\n",
    "else:\n",
    "    labels_to_onehot = ['fame', 'gender', 'occupation']\n",
    "    labels = {}\n",
    "\n",
    "    for label in labels_to_onehot:\n",
    "        unique_classes = len(df[label].unique())\n",
    "        print('{} unique classes in {}'.format(unique_classes, label))\n",
    "        labels_nd = df[label].values  # the values in the respective column\n",
    "        labels[label] = pd.get_dummies(labels_nd)  # one-hot\n",
    "    with open('pickles/labels.pickle', 'wb') as handle:\n",
    "        pickle.dump(labels, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "fame_labels = labels['fame']\n",
    "gender_labels = labels['gender']\n",
    "occ_labels = labels['occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = None\n",
    "vocab_size = 15000\n",
    "\n",
    "if load:\n",
    "    with open('pickles/tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "else:\n",
    "    from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=vocab_size)\n",
    "    tokenizer.fit_on_texts(df.text)\n",
    "    \n",
    "    # saving\n",
    "    with open('pickles/tokenizer.pickle', 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 15000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load:\n",
    "    with open('pickles/textmatrix.pickle', 'rb') as handle:\n",
    "        X = pickle.load(handle)\n",
    "else:\n",
    "    X = tokenizer.texts_to_matrix(df.text, mode='tfidf')\n",
    "    with open('pickles/textmatrix.pickle', 'wb') as handle:\n",
    "        pickle.dump(X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# can safely delete df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = birthyear_labels.shape[0]\n",
    "test_size = int(num_items * 0.2)  # the amount of rows to use as validation set\n",
    "SIZE = num_items - test_size\n",
    "SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and validation set 80:20\n",
    "x_train, x_val = X[:SIZE], X[SIZE:]\n",
    "\n",
    "birthyear_train, birthyear_val = birthyear_labels[:SIZE], birthyear_labels[SIZE:]\n",
    "\n",
    "fame_train, fame_val = fame_labels[:SIZE], fame_labels[SIZE:]\n",
    "\n",
    "gender_train, gender_val = gender_labels[:SIZE], gender_labels[SIZE:]\n",
    "\n",
    "occ_train, occ_val = occ_labels[:SIZE], occ_labels[SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (vocab_size,)\n",
    "input_layer = Input(shape)\n",
    "\n",
    "in_activation = 'relu'\n",
    "branch_activation = 'selu'\n",
    "mid_activation = 'relu'\n",
    "out_activation = 'softmax'  # sigmoid/tanh/relu\n",
    "\n",
    "year_activation = 'sigmoid'\n",
    "\n",
    "_year = 'birthyear_out'\n",
    "_fame = 'fame_out'\n",
    "_gend = 'gender_out'\n",
    "_occu = 'occ_out'\n",
    "\n",
    "\n",
    "INPUT_DIM = 1024\n",
    "DROPOUT = 0.3\n",
    "HIDDEN_DIM = 1024\n",
    "MID_DIM = 128\n",
    "\n",
    "loss_fn = 'categorical_crossentropy'\n",
    "\n",
    "# before splitting categories\n",
    "hidden_layer = Dense(units=INPUT_DIM, activation=in_activation)(input_layer)\n",
    "\n",
    "dropout_layer = Dropout(DROPOUT)(hidden_layer)\n",
    "\n",
    "branch_layer = Dense(units=HIDDEN_DIM, activation=in_activation)(dropout_layer)\n",
    "# birthyear\n",
    "_ = Dense(units=MID_DIM, activation=mid_activation)(branch_layer)\n",
    "birthyear_out = Dense(units=1, activation=year_activation, name=_year)(_)\n",
    "\n",
    "# fame\n",
    "_ = Dense(units=MID_DIM, activation=mid_activation)(branch_layer)\n",
    "fame_out = Dense(units=fame_labels.shape[1], activation=out_activation, name=_fame)(_)\n",
    "\n",
    "# gender\n",
    "_ = Dense(units=MID_DIM, activation=mid_activation)(branch_layer)\n",
    "gender_out = Dense(units=gender_labels.shape[1], activation=out_activation, name=_gend)(_)\n",
    "\n",
    "# occupation\n",
    "_ = Dense(units=MID_DIM, activation=mid_activation)(branch_layer)\n",
    "occ_out = Dense(units=occ_labels.shape[1], activation=out_activation, name=_occu)(_)\n",
    "\n",
    "OUTPUTS = [birthyear_out, fame_out, gender_out, occ_out]\n",
    "model = Model(\n",
    "    inputs=input_layer,\n",
    "    outputs=OUTPUTS)\n",
    "#model = Model(input=input_layer, outputs=fame_out)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={\n",
    "                _year: 'mse',\n",
    "                _fame: loss_fn,\n",
    "                _gend: loss_fn,\n",
    "                _occu: loss_fn},\n",
    "              loss_weights={\n",
    "                _year: 1.2,\n",
    "                _fame: 1.1,\n",
    "                _gend: 1.0,\n",
    "                _occu: 1.2},\n",
    "              metrics={\n",
    "                'birthyear_out': 'mae',\n",
    "                'fame_out': 'accuracy',\n",
    "                'gender_out': 'accuracy',\n",
    "                'occ_out': 'accuracy'}\n",
    "             )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = keras.callbacks.TensorBoard(log_dir='./tensorboard/final_run-10241024-20epoch', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "MIN_CHANGE_REQUIRED = 0  # change in values between epochs\n",
    "EPOCHS_TO_WAIT = 2\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                          patience=EPOCHS_TO_WAIT,\n",
    "                                          baseline=None,\n",
    "                                          restore_best_weights=False)\n",
    "\n",
    "chkpt = keras.callbacks.ModelCheckpoint(filepath='models/best_model.h5', monitor='occ_out_loss', save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [birthyear_train, fame_train, gender_train, occ_train]\n",
    "start_epoch = 0\n",
    "end_epoch = 20\n",
    "bs = 32\n",
    "split_fac = 0\n",
    "callbacks = [board, chkpt]\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=end_epoch,\n",
    "          batch_size=bs,\n",
    "          callbacks=callbacks,\n",
    "          initial_epoch=start_epoch,\n",
    "          validation_split=split_fac,\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"30dropout20epoch.h5\"\n",
    "model.save('models/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 'best_model.h5'\n",
    "model_path = os.path.join(os.getcwd(), 'models', model_name)\n",
    "model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_val, [birthyear_val, fame_val, gender_val, occ_val])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_min = 1940\n",
    "_max = 2008\n",
    "def predict_user(model, user_vec, actual=None, verbose=False):\n",
    "    result = model.predict([[user_vec]])\n",
    "    fame = [\"rising\", \"star\", \"superstar\"]\n",
    "    gender = [\"female\", \"male\", \"nonbinary\"]\n",
    "    occupation = [\"creator\", \"manager\", \"performer\", \"politics\", \"professional\", \"religious\", \"science\", \"sports\"]\n",
    "\n",
    "    birth_pred = result[0][0][0]\n",
    "    fame_pred = result[1][0]\n",
    "    gender_pred = result[2][0]\n",
    "    occ_pred = result[3][0]\n",
    "    \n",
    "    errors = False  # check for errors on the fame/gender/occupation metrics\n",
    "    \n",
    "    year_pred = int(birth_pred * (_max - _min) + _min)\n",
    "    year_real = int(birthyear_val[actual] * (_max - _min) + _min)\n",
    "    \n",
    "    fame_pred = fame[fame_pred.argmax()]\n",
    "    fame_real = fame_val.iloc[actual].idxmax()\n",
    "    \n",
    "    gend_pred = gender[gender_pred.argmax()]\n",
    "    gend_real = gender_val.iloc[actual].idxmax()\n",
    "    \n",
    "    occu_pred = occupation[occ_pred.argmax()]\n",
    "    occu_real = occ_val.iloc[actual].idxmax()\n",
    "    \n",
    "    errors = [fame_pred != fame_real, gend_pred != gend_real, occu_pred != occu_real]\n",
    "\n",
    "    if verbose and sum(errors) != 0:  # only print wrong predictions!\n",
    "        #print(\"Predicted values (real ones in parentheses)\")\n",
    "        print('Birthyear:\\t{} ({})'.format(year_pred, year_real))\n",
    "        print('Fame status:\\t{} ({})'.format(fame_pred, fame_real))\n",
    "        print('Gender:   \\t{} ({})'.format(gend_pred, gend_real))\n",
    "        print('Occupation:\\t{} ({})'.format(occu_pred, occu_real))\n",
    "        # print some of the text...\n",
    "        print(\"--------------------------------------------\")\n",
    "        \n",
    "    return abs(year_pred - year_real), errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birthyear_errors = []\n",
    "errors = {'fame': 0, 'gender': 0, 'occupation': 0}\n",
    "# test_size\n",
    "tests = test_size\n",
    "for i in range(tests):\n",
    "    year_diff, error = predict_user(model, x_val[i], actual=i, verbose=False)\n",
    "    birthyear_errors.append(year_diff)\n",
    "    errors['fame'] += error[0]\n",
    "    errors['gender'] += error[1]\n",
    "    errors['occupation'] += error[2]\n",
    "    \n",
    "    \n",
    "print('Average off by {} years'.format(sum(birthyear_errors)/len(birthyear_errors)))\n",
    "print('Fame err: {}/{}'.format(errors['fame'], tests))\n",
    "print('Gender err: {}/{}'.format(errors['gender'], tests))\n",
    "print('Occupation err: {}/{}'.format(errors['occupation'], tests))\n",
    "\n",
    "# create object with which labels were misclassified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
