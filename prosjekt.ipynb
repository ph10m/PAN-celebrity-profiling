{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "#printmd('**bold**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exists, continue!\n"
     ]
    }
   ],
   "source": [
    "# skip this field if \"combined_set.csv\" exists\n",
    "parsed_csv = 'combined_set.csv'\n",
    "\n",
    "if not os.path.isfile(parsed_csv):\n",
    "    feeds = pd.read_json('./feeds_2000.ndjson', lines=True)\n",
    "    labels = pd.read_json('./labels_2000.ndjson', lines=True)\n",
    "\n",
    "    # not all IDs are found in the tiny labels file, make sure we have a complete (albeit fake, dataset)\n",
    "    import random\n",
    "    valid_ids = list(feeds.id)  # the ids found in the feeds_2000\n",
    "    random.shuffle(valid_ids)  # shuffle these and assign random IDs that exist \n",
    "    labels.id = valid_ids\n",
    "    combined = pd.merge(feeds, labels, on='id')\n",
    "    expanded = combined.set_index(\n",
    "        ['id', 'birthyear', 'fame', 'gender', 'occupation']\n",
    "    )['text'].apply(pd.Series).stack()\n",
    "    expanded = expanded.reset_index()\n",
    "    expanded = expanded.drop(columns=['level_5'])  # level_5 is the auto-generated new column, containing an index\n",
    "\n",
    "    expanded.to_csv(parsed_csv)\n",
    "else:\n",
    "    print('file exists, continue!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), parsed_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5220005, 5)\n",
      "(5219253, 5)\n"
     ]
    }
   ],
   "source": [
    "#data_raw = pd.read_csv(data_path)\n",
    "data_raw = pd.read_csv(open(data_path,'r'), encoding='utf-8', engine='c')\n",
    "data_raw.columns = ['index', 'id', 'birthyear', 'fame', 'gender', 'occupation', 'text']\n",
    "data_raw = data_raw.drop(columns=['index', 'id'])  # no need for any non-label data\n",
    "\n",
    "print(data_raw.shape)  # before dropping NaN values\n",
    "\n",
    "data_raw = data_raw.dropna()\n",
    "data_raw['birthyear'] = data_raw['birthyear'].astype(int)  # from 1978.0 -> 1978\n",
    "print(data_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in data = 5219253\n",
      "Number of columns in data = 5\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Sample data:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birthyear</th>\n",
       "      <th>fame</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>Back at it with @americanidol looking for...he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>Can‚Äôt buy all the happiness in the world, it‚Äôs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>30 down @nytimes ü§ùüß°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>üì∏ @ronyalwin üíò @ New York, New York https://t....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>üéÄ pink it was love at first sight üéÄ @ New York...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>Putting my best foot forward in The Memphis by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>Girls UNITED can never be divided! üëØ‚Äç‚ôÄÔ∏è‚ù§Ô∏è http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>BRB buying The Stephanie bow shoe as an early ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>Connect the dots, bbs  #TheClara - TeamKP @kpc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>Geometry was The Daina‚Äôs favorite subject in s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>We love a Mary June. I mean, Mary Jane. I mean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>WE HAVE ALWAYS BEEN READY FOR THIS GELI OK üçë üçã...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>Ain‚Äôt The Turner a jewel?  üíé - TeamKP @kpcolle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>KICK üë£ BALL üë£ CHANGE in The Jo - TeamKP @kpcol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>All I want for Christmas is The Caine (sorry, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>We love The Sissy as much as we love our own s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>Live in FIVE!  -TeamKP @kpcollections #KatyPer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>T-minus one hour until I‚Äôll be on @QVC showing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>Tune in live now for a chat with @QVC! https:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>WHAT SHE SAID OK\\n    ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è\\n\\n#Repost @r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>Incredibly moving and authentic ‚ù§Ô∏èCongrats fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>PROUD to be covergirl for @FootwearNews &amp; even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>I like when a lone fly catches a ride on an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>Why didn‚Äôt the fettuccine go out for Halloween...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>Ladies, it‚Äôs time to remind them ‚úäüèª</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>RT @CoryBooker: Right, forever vigilant \\n\\nIs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>#TBT to when I got to ‚úî another one off my buc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>Proud of this üë†PLATFORM üë† (yes I did!) to rais...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>*BLOCKS* https://t.co/ntOG1A7ede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>I just cracked my molar in half on a ranch cor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    birthyear  fame gender occupation  \\\n",
       "0        1991  star   male  performer   \n",
       "1        1991  star   male  performer   \n",
       "2        1991  star   male  performer   \n",
       "3        1991  star   male  performer   \n",
       "4        1991  star   male  performer   \n",
       "5        1991  star   male  performer   \n",
       "6        1991  star   male  performer   \n",
       "7        1991  star   male  performer   \n",
       "8        1991  star   male  performer   \n",
       "9        1991  star   male  performer   \n",
       "10       1991  star   male  performer   \n",
       "11       1991  star   male  performer   \n",
       "12       1991  star   male  performer   \n",
       "13       1991  star   male  performer   \n",
       "14       1991  star   male  performer   \n",
       "15       1991  star   male  performer   \n",
       "16       1991  star   male  performer   \n",
       "17       1991  star   male  performer   \n",
       "18       1991  star   male  performer   \n",
       "19       1991  star   male  performer   \n",
       "20       1991  star   male  performer   \n",
       "21       1991  star   male  performer   \n",
       "22       1991  star   male  performer   \n",
       "23       1991  star   male  performer   \n",
       "24       1991  star   male  performer   \n",
       "25       1991  star   male  performer   \n",
       "26       1991  star   male  performer   \n",
       "27       1991  star   male  performer   \n",
       "28       1991  star   male  performer   \n",
       "29       1991  star   male  performer   \n",
       "\n",
       "                                                 text  \n",
       "0   Back at it with @americanidol looking for...he...  \n",
       "1   Can‚Äôt buy all the happiness in the world, it‚Äôs...  \n",
       "2                                 30 down @nytimes ü§ùüß°  \n",
       "3   üì∏ @ronyalwin üíò @ New York, New York https://t....  \n",
       "4   üéÄ pink it was love at first sight üéÄ @ New York...  \n",
       "5   Putting my best foot forward in The Memphis by...  \n",
       "6   Girls UNITED can never be divided! üëØ‚Äç‚ôÄÔ∏è‚ù§Ô∏è http...  \n",
       "7   BRB buying The Stephanie bow shoe as an early ...  \n",
       "8   Connect the dots, bbs  #TheClara - TeamKP @kpc...  \n",
       "9   Geometry was The Daina‚Äôs favorite subject in s...  \n",
       "10  We love a Mary June. I mean, Mary Jane. I mean...  \n",
       "11  WE HAVE ALWAYS BEEN READY FOR THIS GELI OK üçë üçã...  \n",
       "12  Ain‚Äôt The Turner a jewel?  üíé - TeamKP @kpcolle...  \n",
       "13  KICK üë£ BALL üë£ CHANGE in The Jo - TeamKP @kpcol...  \n",
       "14  All I want for Christmas is The Caine (sorry, ...  \n",
       "15  We love The Sissy as much as we love our own s...  \n",
       "16  Live in FIVE!  -TeamKP @kpcollections #KatyPer...  \n",
       "17  T-minus one hour until I‚Äôll be on @QVC showing...  \n",
       "18  Tune in live now for a chat with @QVC! https:/...  \n",
       "19  WHAT SHE SAID OK\\n    ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è\\n\\n#Repost @r...  \n",
       "20  Incredibly moving and authentic ‚ù§Ô∏èCongrats fri...  \n",
       "21  PROUD to be covergirl for @FootwearNews & even...  \n",
       "22  I like when a lone fly catches a ride on an in...  \n",
       "23  Why didn‚Äôt the fettuccine go out for Halloween...  \n",
       "24                Ladies, it‚Äôs time to remind them ‚úäüèª  \n",
       "25  RT @CoryBooker: Right, forever vigilant \\n\\nIs...  \n",
       "26  #TBT to when I got to ‚úî another one off my buc...  \n",
       "27  Proud of this üë†PLATFORM üë† (yes I did!) to rais...  \n",
       "28                   *BLOCKS* https://t.co/ntOG1A7ede  \n",
       "29  I just cracked my molar in half on a ranch cor...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of rows in data =\",data_raw.shape[0])\n",
    "print(\"Number of columns in data =\",data_raw.shape[1])\n",
    "print(\"\\n\")\n",
    "printmd(\"**Sample data:**\")\n",
    "data_raw.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['birthyear', 'fame', 'gender', 'occupation']\n"
     ]
    }
   ],
   "source": [
    "categories = list(data_raw.columns.values)\n",
    "categories = categories[:-1]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_raw\n",
    "# uncomment below to keep a subset of rows for testing\n",
    "numrows = 1000000\n",
    "data = data_raw.loc[np.random.choice(data_raw.index, size=numrows)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanHtml(sentence):\n",
    "    #cleanr = re.compile('<.*?>')\n",
    "    #cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    cleantext = re.sub(r'http\\S+', '', sentence)\n",
    "    return cleantext\n",
    "\n",
    "def cleanRetweet(sentence):\n",
    "    return re.sub(r'rt', '', sentence)\n",
    "\n",
    "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "\n",
    "def cleanMentions(sentence):\n",
    "    return re.sub(r'@#?\\b\\w\\w+\\b', '', sentence)\n",
    "\n",
    "def keepAlphaHash(sentence):\n",
    "    return ' '.join([w for w in sentence.split() if w.isalpha() or '#' in w])\n",
    "\n",
    "def emptyToNan(sentence):\n",
    "    if len(sentence) < 1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birthyear</th>\n",
       "      <th>fame</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3321958</th>\n",
       "      <td>1971</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>i know there is no momentum in a baseball seri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595074</th>\n",
       "      <td>1973</td>\n",
       "      <td>star</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>#repost umarƒ±m i√ßine sindiƒüi kadar yolu da a√ßƒ±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679436</th>\n",
       "      <td>1952</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>creator</td>\n",
       "      <td>wow farewell to the obamas struck me as farewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718310</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>thug life #throwbackthursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3781527</th>\n",
       "      <td>1986</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>musiga commends president mahama for setting u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247362</th>\n",
       "      <td>1982</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>i care what do we have the best celebrations i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166763</th>\n",
       "      <td>1974</td>\n",
       "      <td>superstar</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>literally in my hotel room alone making myself...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280593</th>\n",
       "      <td>1949</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>science</td>\n",
       "      <td>ready</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304993</th>\n",
       "      <td>1983</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>copenhagen i am in you playing tonight at pump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4445853</th>\n",
       "      <td>1997</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>animalstilo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873694</th>\n",
       "      <td>1981</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>feel like writing for a few minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345939</th>\n",
       "      <td>1990</td>\n",
       "      <td>rising</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>never everyone is so nasty online but no one e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942699</th>\n",
       "      <td>1985</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>via heres a sneak peek of feature model and hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537128</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>ŸÑŸÖÿß ÿ®ŸÇŸàŸÑ ÿπŸÜŸÉ ÿ≥ÿ™ ÿßŸÑÿ≥ÿ™ÿßÿ™ ŸÖÿß ÿ®ŸÉŸàŸÜ ÿπŸÖ ÿ®ÿßŸÑÿ∫ ŸáŸäŸÅÿß ÿßŸÜ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189902</th>\n",
       "      <td>1966</td>\n",
       "      <td>star</td>\n",
       "      <td>female</td>\n",
       "      <td>politics</td>\n",
       "      <td>be back john same time same place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722638</th>\n",
       "      <td>1990</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>thank u sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3045750</th>\n",
       "      <td>1980</td>\n",
       "      <td>star</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>alhamdulillah syukur pada tuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925021</th>\n",
       "      <td>1992</td>\n",
       "      <td>rising</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>i care more for life cycle i spend a lot of ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3027862</th>\n",
       "      <td>1980</td>\n",
       "      <td>star</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>thanks my brother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855367</th>\n",
       "      <td>1984</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>creator</td>\n",
       "      <td>legends of the summer out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836208</th>\n",
       "      <td>1978</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>creator</td>\n",
       "      <td>its all just a jape a game between old members...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742782</th>\n",
       "      <td>1995</td>\n",
       "      <td>rising</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>yep you know youre a badass when performs an h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4708474</th>\n",
       "      <td>1963</td>\n",
       "      <td>superstar</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>recorded at the legendary with one direction p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976813</th>\n",
       "      <td>1977</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>creator</td>\n",
       "      <td>a few of the answers jerry lewis gave to the q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480164</th>\n",
       "      <td>1976</td>\n",
       "      <td>star</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>msm react to this you and i must share share s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905453</th>\n",
       "      <td>1973</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>what a way to finish at the lane special feeli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110834</th>\n",
       "      <td>1997</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>the yc strategy deck is significantly uglier b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4688591</th>\n",
       "      <td>1980</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>#rouhani interview with to be aired on #nbcnig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2854665</th>\n",
       "      <td>1959</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>creator</td>\n",
       "      <td>amoebas are really cool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138470</th>\n",
       "      <td>1964</td>\n",
       "      <td>superstar</td>\n",
       "      <td>male</td>\n",
       "      <td>politics</td>\n",
       "      <td>#latalksmj are any of the tracks from the thri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         birthyear       fame  gender occupation  \\\n",
       "3321958       1971       star    male     sports   \n",
       "595074        1973       star  female  performer   \n",
       "1679436       1952       star    male    creator   \n",
       "718310        1991       star    male  performer   \n",
       "3781527       1986       star    male     sports   \n",
       "3247362       1982       star    male     sports   \n",
       "5166763       1974  superstar    male  performer   \n",
       "280593        1949       star    male    science   \n",
       "4304993       1983       star    male     sports   \n",
       "4445853       1997       star    male     sports   \n",
       "873694        1981       star    male     sports   \n",
       "2345939       1990     rising    male     sports   \n",
       "3942699       1985       star    male     sports   \n",
       "537128        1991       star    male  performer   \n",
       "1189902       1966       star  female   politics   \n",
       "722638        1990       star    male     sports   \n",
       "3045750       1980       star  female  performer   \n",
       "1925021       1992     rising    male     sports   \n",
       "3027862       1980       star  female  performer   \n",
       "855367        1984       star    male    creator   \n",
       "2836208       1978       star    male    creator   \n",
       "3742782       1995     rising    male     sports   \n",
       "4708474       1963  superstar    male  performer   \n",
       "1976813       1977       star    male    creator   \n",
       "3480164       1976       star  female  performer   \n",
       "1905453       1973       star    male  performer   \n",
       "5110834       1997       star    male     sports   \n",
       "4688591       1980       star    male     sports   \n",
       "2854665       1959       star    male    creator   \n",
       "3138470       1964  superstar    male   politics   \n",
       "\n",
       "                                                      text  \n",
       "3321958  i know there is no momentum in a baseball seri...  \n",
       "595074   #repost umarƒ±m i√ßine sindiƒüi kadar yolu da a√ßƒ±...  \n",
       "1679436  wow farewell to the obamas struck me as farewe...  \n",
       "718310                        thug life #throwbackthursday  \n",
       "3781527  musiga commends president mahama for setting u...  \n",
       "3247362  i care what do we have the best celebrations i...  \n",
       "5166763  literally in my hotel room alone making myself...  \n",
       "280593                                               ready  \n",
       "4304993  copenhagen i am in you playing tonight at pump...  \n",
       "4445853                                        animalstilo  \n",
       "873694                 feel like writing for a few minutes  \n",
       "2345939  never everyone is so nasty online but no one e...  \n",
       "3942699  via heres a sneak peek of feature model and hi...  \n",
       "537128   ŸÑŸÖÿß ÿ®ŸÇŸàŸÑ ÿπŸÜŸÉ ÿ≥ÿ™ ÿßŸÑÿ≥ÿ™ÿßÿ™ ŸÖÿß ÿ®ŸÉŸàŸÜ ÿπŸÖ ÿ®ÿßŸÑÿ∫ ŸáŸäŸÅÿß ÿßŸÜ...  \n",
       "1189902                  be back john same time same place  \n",
       "722638                                         thank u sir  \n",
       "3045750                    alhamdulillah syukur pada tuhan  \n",
       "1925021  i care more for life cycle i spend a lot of ti...  \n",
       "3027862                                  thanks my brother  \n",
       "855367                           legends of the summer out  \n",
       "2836208  its all just a jape a game between old members...  \n",
       "3742782  yep you know youre a badass when performs an h...  \n",
       "4708474  recorded at the legendary with one direction p...  \n",
       "1976813  a few of the answers jerry lewis gave to the q...  \n",
       "3480164  msm react to this you and i must share share s...  \n",
       "1905453  what a way to finish at the lane special feeli...  \n",
       "5110834  the yc strategy deck is significantly uglier b...  \n",
       "4688591  #rouhani interview with to be aired on #nbcnig...  \n",
       "2854665                            amoebas are really cool  \n",
       "3138470  #latalksmj are any of the tracks from the thri...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['text'].str.lower()\n",
    "data['text'] = data['text'].apply(cleanRetweet)\n",
    "data['text'] = data['text'].apply(cleanHtml)\n",
    "data['text'] = data['text'].apply(cleanPunc)\n",
    "data['text'] = data['text'].apply(keepAlphaHash)\n",
    "\n",
    "# prune empty sentences, replace with NaN and use the built-in dropna() func\n",
    "data['text'] = data['text'].apply(emptyToNan)\n",
    "data = data.dropna()\n",
    "data.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birthyear</th>\n",
       "      <th>fame</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3321958</th>\n",
       "      <td>1971</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>know    momentum   baseball series  boy    ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595074</th>\n",
       "      <td>1973</td>\n",
       "      <td>star</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>#repost umarƒ±m i√ßine sindiƒüi kadar yolu da a√ßƒ±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679436</th>\n",
       "      <td>1952</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>creator</td>\n",
       "      <td>wow farewell   obamas struck   farewell     we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718310</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>thug life #throwbackthursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3781527</th>\n",
       "      <td>1986</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>musiga commends president mahama  setting  tou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247362</th>\n",
       "      <td>1982</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>care      best celebrations   league</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166763</th>\n",
       "      <td>1974</td>\n",
       "      <td>superstar</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>literally   hotel room alone making  laugh    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280593</th>\n",
       "      <td>1949</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>science</td>\n",
       "      <td>ready</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304993</th>\n",
       "      <td>1983</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>copenhagen     playing tonight  pumpehuset  ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4445853</th>\n",
       "      <td>1997</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>animalstilo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873694</th>\n",
       "      <td>1981</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>feel like writing    minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345939</th>\n",
       "      <td>1990</td>\n",
       "      <td>rising</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>never everyone   nasty online    ever approach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942699</th>\n",
       "      <td>1985</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>via heres  sneak peek  feature model   new sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537128</th>\n",
       "      <td>1991</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>ŸÑŸÖÿß ÿ®ŸÇŸàŸÑ ÿπŸÜŸÉ ÿ≥ÿ™ ÿßŸÑÿ≥ÿ™ÿßÿ™ ŸÖÿß ÿ®ŸÉŸàŸÜ ÿπŸÖ ÿ®ÿßŸÑÿ∫ ŸáŸäŸÅÿß ÿßŸÜ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189902</th>\n",
       "      <td>1966</td>\n",
       "      <td>star</td>\n",
       "      <td>female</td>\n",
       "      <td>politics</td>\n",
       "      <td>back john  time  place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722638</th>\n",
       "      <td>1990</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>thank u sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3045750</th>\n",
       "      <td>1980</td>\n",
       "      <td>star</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>alhamdulillah syukur pada tuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925021</th>\n",
       "      <td>1992</td>\n",
       "      <td>rising</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>care   life cycle  spend  lot  time  here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3027862</th>\n",
       "      <td>1980</td>\n",
       "      <td>star</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>thanks  brother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855367</th>\n",
       "      <td>1984</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>creator</td>\n",
       "      <td>legends   summer out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836208</th>\n",
       "      <td>1978</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>creator</td>\n",
       "      <td>jape  game  old members   oxford universit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742782</th>\n",
       "      <td>1995</td>\n",
       "      <td>rising</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>yep  know youre  badass  performs  hour plus  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4708474</th>\n",
       "      <td>1963</td>\n",
       "      <td>superstar</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>recorded   legendary   direction produced   fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976813</th>\n",
       "      <td>1977</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>creator</td>\n",
       "      <td>answers jerry lewis gave   question   want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480164</th>\n",
       "      <td>1976</td>\n",
       "      <td>star</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>msm react      must share share share send   p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905453</th>\n",
       "      <td>1973</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>performer</td>\n",
       "      <td>way  finish   lane special feeling  score  w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110834</th>\n",
       "      <td>1997</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>yc strategy deck  significantly uglier  says ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4688591</th>\n",
       "      <td>1980</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>sports</td>\n",
       "      <td>#rouhani interview    aired  #nbcnightlynews  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2854665</th>\n",
       "      <td>1959</td>\n",
       "      <td>star</td>\n",
       "      <td>male</td>\n",
       "      <td>creator</td>\n",
       "      <td>amoebas  really cool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138470</th>\n",
       "      <td>1964</td>\n",
       "      <td>superstar</td>\n",
       "      <td>male</td>\n",
       "      <td>politics</td>\n",
       "      <td>#latalksmj     tracks   thriller sessions  qui...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         birthyear       fame  gender occupation  \\\n",
       "3321958       1971       star    male     sports   \n",
       "595074        1973       star  female  performer   \n",
       "1679436       1952       star    male    creator   \n",
       "718310        1991       star    male  performer   \n",
       "3781527       1986       star    male     sports   \n",
       "3247362       1982       star    male     sports   \n",
       "5166763       1974  superstar    male  performer   \n",
       "280593        1949       star    male    science   \n",
       "4304993       1983       star    male     sports   \n",
       "4445853       1997       star    male     sports   \n",
       "873694        1981       star    male     sports   \n",
       "2345939       1990     rising    male     sports   \n",
       "3942699       1985       star    male     sports   \n",
       "537128        1991       star    male  performer   \n",
       "1189902       1966       star  female   politics   \n",
       "722638        1990       star    male     sports   \n",
       "3045750       1980       star  female  performer   \n",
       "1925021       1992     rising    male     sports   \n",
       "3027862       1980       star  female  performer   \n",
       "855367        1984       star    male    creator   \n",
       "2836208       1978       star    male    creator   \n",
       "3742782       1995     rising    male     sports   \n",
       "4708474       1963  superstar    male  performer   \n",
       "1976813       1977       star    male    creator   \n",
       "3480164       1976       star  female  performer   \n",
       "1905453       1973       star    male  performer   \n",
       "5110834       1997       star    male     sports   \n",
       "4688591       1980       star    male     sports   \n",
       "2854665       1959       star    male    creator   \n",
       "3138470       1964  superstar    male   politics   \n",
       "\n",
       "                                                      text  \n",
       "3321958   know    momentum   baseball series  boy    ex...  \n",
       "595074   #repost umarƒ±m i√ßine sindiƒüi kadar yolu da a√ßƒ±...  \n",
       "1679436  wow farewell   obamas struck   farewell     we...  \n",
       "718310                        thug life #throwbackthursday  \n",
       "3781527  musiga commends president mahama  setting  tou...  \n",
       "3247362               care      best celebrations   league  \n",
       "5166763  literally   hotel room alone making  laugh    ...  \n",
       "280593                                               ready  \n",
       "4304993  copenhagen     playing tonight  pumpehuset  ti...  \n",
       "4445853                                        animalstilo  \n",
       "873694                        feel like writing    minutes  \n",
       "2345939  never everyone   nasty online    ever approach...  \n",
       "3942699  via heres  sneak peek  feature model   new sho...  \n",
       "537128   ŸÑŸÖÿß ÿ®ŸÇŸàŸÑ ÿπŸÜŸÉ ÿ≥ÿ™ ÿßŸÑÿ≥ÿ™ÿßÿ™ ŸÖÿß ÿ®ŸÉŸàŸÜ ÿπŸÖ ÿ®ÿßŸÑÿ∫ ŸáŸäŸÅÿß ÿßŸÜ...  \n",
       "1189902                             back john  time  place  \n",
       "722638                                         thank u sir  \n",
       "3045750                    alhamdulillah syukur pada tuhan  \n",
       "1925021          care   life cycle  spend  lot  time  here  \n",
       "3027862                                    thanks  brother  \n",
       "855367                                legends   summer out  \n",
       "2836208      jape  game  old members   oxford universit...  \n",
       "3742782  yep  know youre  badass  performs  hour plus  ...  \n",
       "4708474  recorded   legendary   direction produced   fr...  \n",
       "1976813      answers jerry lewis gave   question   want...  \n",
       "3480164  msm react      must share share share send   p...  \n",
       "1905453    way  finish   lane special feeling  score  w...  \n",
       "5110834   yc strategy deck  significantly uglier  says ...  \n",
       "4688591  #rouhani interview    aired  #nbcnightlynews  ...  \n",
       "2854665                               amoebas  really cool  \n",
       "3138470  #latalksmj     tracks   thriller sessions  qui...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])\n",
    "re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
    "def removeStopWords(sentence):\n",
    "    global re_stop_words\n",
    "    return re_stop_words.sub(\" \", sentence)\n",
    "\n",
    "data['text'] = data['text'].apply(removeStopWords)\n",
    "data.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "\n",
    "data['text'] = data['text'].apply(stemming)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('PREPROCESSED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('PREPROCESSED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, random_state=42, test_size=0.20, shuffle=True)\n",
    "\n",
    "#train.to_csv('formatted/train.csv')\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['text']\n",
    "test_text = test['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#x = v.fit_transform(df['Review'].values.astype('U'))  ## Even astype(str) would work\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
    "vectorizer.fit(train_text)\n",
    "vectorizer.fit(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer.transform(train_text)\n",
    "y_train = train.drop(labels = ['text'], axis=1)\n",
    "\n",
    "x_test = vectorizer.transform(test_text)\n",
    "y_test = test.drop(labels = ['text'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Label Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Multiple Binary Classifications - (One Vs Rest Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(data.columns.values)\n",
    "categories = categories[:-1]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    printmd('**Processing {} comments...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(x_train, train[category])\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Multiple Binary Classifications - (Binary Relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no supported conversion for types: (dtype('O'),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Downloads/proj/venv/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36masformat\u001b[0;34m(self, format, copy)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/proj/venv/lib/python3.7/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtocsc\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/proj/venv/lib/python3.7/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no supported conversion for types: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/proj/venv/lib/python3.7/site-packages/skmultilearn/problem_transform/br.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    148\u001b[0m             X, sparse_format='csr', enforce_sparse=True)\n\u001b[1;32m    149\u001b[0m         y = self._ensure_output_format(\n\u001b[0;32m--> 150\u001b[0;31m             y, sparse_format='csc', enforce_sparse=True)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifiers_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/proj/venv/lib/python3.7/site-packages/skmultilearn/base/base.py\u001b[0m in \u001b[0;36m_ensure_output_format\u001b[0;34m(self, matrix, sparse_format, enforce_sparse)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmatrix_creation_function_for_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/proj/venv/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     81\u001b[0m                                  \"\".format(self.format))\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Read matrix dimensions given, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/proj/venv/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/proj/venv/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36masformat\u001b[0;34m(self, format, copy)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;31m###################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/proj/venv/lib/python3.7/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtocsc\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             coo_tocsr(N, M, self.nnz, col, row, self.data,\n",
      "\u001b[0;32m~/Downloads/proj/venv/lib/python3.7/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no supported conversion for types: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# using binary relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "\n",
    "# train\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(y_test,predictions))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Classifier Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using classifier chains\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# initialize classifier chains multi-label classifier\n",
    "classifier = ClassifierChain(LogisticRegression())\n",
    "\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(y_test,predictions))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Label Powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Label Powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# initialize label powerset multi-label classifier\n",
    "classifier = LabelPowerset(LogisticRegression())\n",
    "\n",
    "# train\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(y_test,predictions))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
