{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "# preprocess!\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['rt'])  # remove the retweet tag!\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sents(sent):\n",
    "    return ' '.join(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links_and_html(sentence):\n",
    "    sentence = re.sub(r'http\\S+', '', sentence)\n",
    "    sentence = re.sub(r'<[^<]+?>', '', sentence)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "def remove_punct(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "\n",
    "def remove_mentions(sentence):\n",
    "    # keep the @ to check for mentions among separate groups\n",
    "    return re.sub(r'@#?\\b\\w\\w+\\b', '@', sentence)\n",
    "\n",
    "def valid_token(tok):\n",
    "    if '#' in tok:\n",
    "        # make sure the hashtag is alphanumeric (avoiding arabic etc)\n",
    "        return re.sub('[^0-9a-zA-Z]+', '', tok) != ''\n",
    "    non_stop = tok not in stop_words\n",
    "    no_rt = 'rt' not in tok\n",
    "    is_latin = re.sub('[^0-9a-zA-Z]+', '', tok) == tok\n",
    "    return is_latin and non_stop\n",
    "\n",
    "def clean_stopwords(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    return ' '.join([t for t in tokens if valid_token(t)])\n",
    "        \n",
    "def stem(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    tokens = [stemmer.stem(t) for t in tokens]\n",
    "    return ' '.join([t for t in tokens if valid_token(t)])\n",
    "\n",
    "def empty_to_nan(sentence):\n",
    "    if len(sentence) < 1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return sentence\n",
    "\n",
    "def clean_all(s):\n",
    "    #s = s.lower()\n",
    "    s = remove_links_and_html(s)\n",
    "    s = remove_punct(s)\n",
    "    s = remove_mentions(s)\n",
    "    s = clean_stopwords(s)\n",
    "    # stemming is slow on loads of data, consider uncommenting on big sets.\n",
    "    #s = stem(s)\n",
    "    # finally, make sure we have no empty texts\n",
    "    s = empty_to_nan(s)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT/feed00.csv\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\SPLIT\\feed00\n",
      "      id                                               text  birthyear  \\\n",
      "0  22704  Back at it with @americanidol looking for...he...       1984   \n",
      "1  46305  The last presidential election turned on fewer...       1961   \n",
      "2  30260  Angels ðŸ˜‡ \\n@RobbieWilliams\\nhttps://t.co/A6...       1989   \n",
      "3   4874  Listen to â€œShallowâ€�, â€œAlways Remember Us...       1986   \n",
      "4  41392  So happy for my island! Vote for Madeira, for ...       1985   \n",
      "\n",
      "        fame  gender occupation  \n",
      "0  superstar  female  performer  \n",
      "1  superstar    male   politics  \n",
      "2  superstar  female  performer  \n",
      "3  superstar  female    creator  \n",
      "4  superstar    male    manager  \n",
      "...cleaning\n",
      "151.7535059452057\n",
      "SPLIT/feed01.csv\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\SPLIT\\feed01\n",
      "      id                                               text  birthyear  \\\n",
      "0  48084  Paul Manafort is spending a lot of time with R...       1976   \n",
      "1  33848  theneighborhood Is going purple for #SpiritDay...       1969   \n",
      "2   3930  â€œCome fly with me...â€� @sixsenseszilpasyon ...       1986   \n",
      "3   9221  Yassssss ðŸ™ŒðŸ�½ https://t.co/egBF3OBKoY RT @...       1987   \n",
      "4   7380  RT @ChampionsLeague: ðŸ˜œ Cheeky \\nâš¡ï¸� Elec...       1990   \n",
      "\n",
      "        fame  gender occupation  \n",
      "0  superstar    male    creator  \n",
      "1  superstar  female  performer  \n",
      "2  superstar  female  performer  \n",
      "3  superstar  female  performer  \n",
      "4  superstar    male     sports  \n",
      "...cleaning\n",
      "150.75311493873596\n",
      "SPLIT/feed02.csv\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\SPLIT\\feed02\n",
      "      id                                               text  birthyear  \\\n",
      "0  25541  RT @RealKevinNash: One for the ages. @HulkHoga...       1955   \n",
      "1  22004  https://t.co/4OhGAnHa40 @CeeVee12 @FIFAWorldCu...       1993   \n",
      "2  30510  Welp @VonMiller said they were going to KICK t...       1983   \n",
      "3  25939  Congrats @HCFBMaroons on your playoff-clinchin...       1988   \n",
      "4    972  #MartesDeLectura: En esta obra se exponen las ...       1940   \n",
      "\n",
      "        fame gender occupation  \n",
      "0  superstar   male     sports  \n",
      "1  superstar   male     sports  \n",
      "2  superstar   male     sports  \n",
      "3  superstar   male     sports  \n",
      "4  superstar   male   politics  \n",
      "...cleaning\n",
      "144.8017418384552\n",
      "SPLIT/feed03.csv\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\SPLIT\\feed03\n",
      "      id                                               text  birthyear  \\\n",
      "0  24811  RT @maliniagarwal: Honestly I'd like to take a...       1982   \n",
      "1   4969  RT @TeamQuetta: .@UmerAmin200 hit three sixes ...       1989   \n",
      "2  25912  My blood moon. https://t.co/MLpYviBu1S What a ...       1981   \n",
      "3  42277  Watch the former Jeff Beck Group bandmates per...       1944   \n",
      "4  20801  RT @FancyvandeVorst: Great opening @BioArtLab ...       1941   \n",
      "\n",
      "        fame  gender occupation  \n",
      "0  superstar    male  performer  \n",
      "1  superstar    male     sports  \n",
      "2  superstar  female    creator  \n",
      "3  superstar    male  performer  \n",
      "4  superstar  female   politics  \n",
      "...cleaning\n",
      "146.99304056167603\n",
      "SPLIT/feed04.csv\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\SPLIT\\feed04\n",
      "      id                                               text  birthyear  fame  \\\n",
      "0   5600  @ThatAnt_ @SupportAVFC He supports Tamworth FC...       1976  star   \n",
      "1  39940  @arielhelwani Bullshit, Ariel. This has to be ...       1987  star   \n",
      "2  20120  RT @WarrenBuffetIG: Here's what's cool:\\n\\n1 s...       1985  star   \n",
      "3  47634  @nhlaka_madwe @andileluck19 @sekojafta @Sibzma...       1995  star   \n",
      "4  36342  @Atlanta11286 @Thorkild_Olesen @kristeligt For...       1969  star   \n",
      "\n",
      "   gender occupation  \n",
      "0    male  performer  \n",
      "1    male     sports  \n",
      "2  female  performer  \n",
      "3    male     sports  \n",
      "4    male   politics  \n",
      "...cleaning\n",
      "145.24081826210022\n",
      "SPLIT/feed05.csv\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\SPLIT\\feed05\n",
      "      id                                               text  birthyear  fame  \\\n",
      "0  32709  RT @oren_cass: â€œIâ€™m for globalization and ...       1984  star   \n",
      "1    481  RT @5liveSport: Coming up from 7pm reactions t...       1965  star   \n",
      "2  17976  @Jarrodcroker @Uz_Khawaja What he get RT @AskK...       1986  star   \n",
      "3  44142  This is why itâ€™s so important to consume mul...       1970  star   \n",
      "4   1597  Clearly. The syllabus is biased against the co...       1980  star   \n",
      "\n",
      "   gender occupation  \n",
      "0    male    creator  \n",
      "1    male     sports  \n",
      "2    male     sports  \n",
      "3  female    creator  \n",
      "4    male  performer  \n",
      "...cleaning\n"
     ]
    }
   ],
   "source": [
    "samples = glob.glob(os.path.join(os.getcwd(), 'SPLIT') + '/*')\n",
    "labels = pd.read_json('../data/labels.ndjson', lines=True)\n",
    "for sample in samples:\n",
    "    csvname = 'SPLIT/' + sample[-6:] + '.csv'\n",
    "    print(csvname)\n",
    "    print(sample)\n",
    "    df = pd.read_json(sample, lines=True)\n",
    "    combined = pd.merge(df, labels, on='id')\n",
    "    #combined = combined.drop(columns=['id'])  # no need for any non-label data\n",
    "    combined['text'] = combined['text'].apply(merge_sents)\n",
    "    combined = combined.dropna()\n",
    "    print(combined.head())\n",
    "    del df\n",
    "    \n",
    "    start = time.time()\n",
    "    print('...cleaning')\n",
    "    combined['text'] = combined['text'].str.lower()\n",
    "    combined['text'] = combined['text'].apply(clean_all)\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "\n",
    "    # prune empty texts\n",
    "    combined = combined.dropna()\n",
    "    combined.to_csv(csvname, header=False, index=False)\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
