{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\samples\\feed00-sample.ndjson\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\samples\\feed01-sample.ndjson\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\samples\\feed02-sample.ndjson\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\samples\\feed03-sample.ndjson\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\samples\\feed04-sample.ndjson\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\samples\\feed05-sample.ndjson\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\samples\\feed06-sample.ndjson\n"
     ]
    }
   ],
   "source": [
    "final_df = None\n",
    "if not os.path.isfile('expanded.csv'):\n",
    "    samples = glob.glob(os.path.join(os.getcwd(), 'samples') + '/*.ndjson')\n",
    "\n",
    "    dfs = []\n",
    "    for sample in samples:\n",
    "        print(sample)\n",
    "        df = pd.read_json(sample, lines=True)\n",
    "        dfs.append(df)\n",
    "\n",
    "    final_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    labels = pd.read_json('../data/labels.ndjson', lines=True)\n",
    "    combined = pd.merge(final_df, labels, on='id')\n",
    "    expanded = combined.set_index(\n",
    "        ['id', 'birthyear', 'fame', 'gender', 'occupation']\n",
    "    )['text'].apply(pd.Series).stack()\n",
    "    expanded = expanded.reset_index()\n",
    "    expanded = expanded.drop(columns=['level_5'])  # level_5 is the auto-generated new column, containing an index\n",
    "\n",
    "    expanded.to_csv('expanded.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12587</td>\n",
       "      <td>[RT @EdinburghJudo: Friday Squad girls, provid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2306</td>\n",
       "      <td>[An elected Matthew Guy Liberal Nationals Gove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19951</td>\n",
       "      <td>[YAAAAASSS this is awesome. Over here in Michi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13084</td>\n",
       "      <td>[RT @EsquireClassic: Mortal Combat: https://t....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22726</td>\n",
       "      <td>[How often does our brain focus on whats wrong...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text\n",
       "0  12587  [RT @EdinburghJudo: Friday Squad girls, provid...\n",
       "1   2306  [An elected Matthew Guy Liberal Nationals Gove...\n",
       "2  19951  [YAAAAASSS this is awesome. Over here in Michi...\n",
       "3  13084  [RT @EsquireClassic: Mortal Combat: https://t....\n",
       "4  22726  [How often does our brain focus on whats wrong..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15962300, 5)\n",
      "(15962300, 5)\n"
     ]
    }
   ],
   "source": [
    "if not final_df:  # make sure we didn't write to a csv\n",
    "    data_path = os.path.join(os.getcwd(), 'expanded.csv')\n",
    "    data_raw = pd.read_csv(data_path)\n",
    "    #data_raw = pd.read_csv(open(data_path,'r'), encoding='utf-8', engine='c')\n",
    "    data_raw.columns = ['index', 'id', 'birthyear', 'fame', 'gender', 'occupation', 'text']\n",
    "    data_raw = data_raw.drop(columns=['index', 'id'])  # no need for any non-label data\n",
    "\n",
    "    print(data_raw.shape)  # before dropping NaN values\n",
    "\n",
    "    data_raw = data_raw.dropna()\n",
    "    data_raw['birthyear'] = data_raw['birthyear'].astype(int)  # from 1978.0 -> 1978\n",
    "    print(data_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.head()\n",
    "data = data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess!\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['rt'])  # remove the retweet tag!\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links_and_html(sentence):\n",
    "    sentence = re.sub(r'http\\S+', '', sentence)\n",
    "    sentence = re.sub(r'<[^<]+?>', '', sentence)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "def remove_punct(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "\n",
    "def remove_mentions(sentence):\n",
    "    return re.sub(r'@#?\\b\\w\\w+\\b', '', sentence)\n",
    "\n",
    "def valid_token(tok):\n",
    "    if '#' in tok:\n",
    "        # make sure the hashtag is alphanumeric (avoiding arabic etc)\n",
    "        return re.sub('[^0-9a-zA-Z]+', '', tok) != ''\n",
    "    non_stop = tok not in stop_words\n",
    "    no_rt = 'rt' not in tok\n",
    "    is_latin = re.sub('[^0-9a-zA-Z]+', '', tok) == tok\n",
    "    return is_latin and non_stop\n",
    "\n",
    "def clean_stopwords(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    return ' '.join([t for t in tokens if valid_token(t)])\n",
    "        \n",
    "def stem(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    tokens = [stemmer.stem(t) for t in tokens]\n",
    "    return ' '.join([t for t in tokens if valid_token(t)])\n",
    "\n",
    "def empty_to_nan(sentence):\n",
    "    if len(sentence) < 1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return sentence\n",
    "\n",
    "def clean_all(s):\n",
    "    #s = s.lower()\n",
    "    s = remove_links_and_html(s)\n",
    "    s = remove_punct(s)\n",
    "    s = remove_mentions(s)\n",
    "    s = clean_stopwords(s)\n",
    "    # stemming is slow on loads of data, consider uncommenting on big sets.\n",
    "    #s = stem(s)\n",
    "    # finally, make sure we have no empty texts\n",
    "    s = empty_to_nan(s)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606.405600309372\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birthyear</th>\n",
       "      <th>fame</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>back looking circa early coeur dalene idaho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>buy happiness world state mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>new york new york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>pink love first sight new york new york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>putting best foot forward memphis #ffanyâ€™s 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>girls united never divided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>brb buying stephanie bow shoe early christmas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>connect dots bbs #theclara teamkp #katyperryonqvc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>geometry favorite subject school #octagonheel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>love mary june mean mary jane mean june teamkp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>always ready geli ok teamkp #katyperryonqvc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>turner jewel teamkp #katyperryonqvc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>kick ball change jo teamkp #katyperryonqvc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>want christmas caine sorry teamkp #katyperryonqvc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>love sissy much love sissy teamkp #katyperryonqvc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>live five #katyperryonqvc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>one hour showing shoes aka one hour see living...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>tune live chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>said ok #repost good morning america awake mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>incredibly moving authentic friends #bradleyco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>proud covergirl even prouder announce 10 10 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>like lone fly catches ride international fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>fettuccine go halloween alfredo florence italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>ladies time remind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>right forever vigilant always stronger wrong t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>#tbt got another one bucket list sing la philh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>proud platform yes raise awareness breast canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>cracked molar half ranch brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1984</td>\n",
       "      <td>superstar</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>thats girl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    birthyear       fame  gender occupation  \\\n",
       "0        1984  superstar  female  performer   \n",
       "1        1984  superstar  female  performer   \n",
       "2        1984  superstar  female  performer   \n",
       "3        1984  superstar  female  performer   \n",
       "4        1984  superstar  female  performer   \n",
       "5        1984  superstar  female  performer   \n",
       "6        1984  superstar  female  performer   \n",
       "7        1984  superstar  female  performer   \n",
       "8        1984  superstar  female  performer   \n",
       "9        1984  superstar  female  performer   \n",
       "10       1984  superstar  female  performer   \n",
       "11       1984  superstar  female  performer   \n",
       "12       1984  superstar  female  performer   \n",
       "13       1984  superstar  female  performer   \n",
       "14       1984  superstar  female  performer   \n",
       "15       1984  superstar  female  performer   \n",
       "16       1984  superstar  female  performer   \n",
       "17       1984  superstar  female  performer   \n",
       "18       1984  superstar  female  performer   \n",
       "19       1984  superstar  female  performer   \n",
       "20       1984  superstar  female  performer   \n",
       "21       1984  superstar  female  performer   \n",
       "22       1984  superstar  female  performer   \n",
       "23       1984  superstar  female  performer   \n",
       "24       1984  superstar  female  performer   \n",
       "25       1984  superstar  female  performer   \n",
       "26       1984  superstar  female  performer   \n",
       "27       1984  superstar  female  performer   \n",
       "29       1984  superstar  female  performer   \n",
       "30       1984  superstar  female  performer   \n",
       "\n",
       "                                                 text  \n",
       "0         back looking circa early coeur dalene idaho  \n",
       "1                      buy happiness world state mind  \n",
       "2                                                  30  \n",
       "3                                   new york new york  \n",
       "4             pink love first sight new york new york  \n",
       "5   putting best foot forward memphis #ffanyâ€™s 2...  \n",
       "6                          girls united never divided  \n",
       "7   brb buying stephanie bow shoe early christmas ...  \n",
       "8   connect dots bbs #theclara teamkp #katyperryonqvc  \n",
       "9   geometry favorite subject school #octagonheel ...  \n",
       "10  love mary june mean mary jane mean june teamkp...  \n",
       "11        always ready geli ok teamkp #katyperryonqvc  \n",
       "12                turner jewel teamkp #katyperryonqvc  \n",
       "13         kick ball change jo teamkp #katyperryonqvc  \n",
       "14  want christmas caine sorry teamkp #katyperryonqvc  \n",
       "15  love sissy much love sissy teamkp #katyperryonqvc  \n",
       "16                          live five #katyperryonqvc  \n",
       "17  one hour showing shoes aka one hour see living...  \n",
       "18                                     tune live chat  \n",
       "19  said ok #repost good morning america awake mor...  \n",
       "20  incredibly moving authentic friends #bradleyco...  \n",
       "21  proud covergirl even prouder announce 10 10 10...  \n",
       "22  like lone fly catches ride international fligh...  \n",
       "23     fettuccine go halloween alfredo florence italy  \n",
       "24                                 ladies time remind  \n",
       "25  right forever vigilant always stronger wrong t...  \n",
       "26  #tbt got another one bucket list sing la philh...  \n",
       "27  proud platform yes raise awareness breast canc...  \n",
       "29                     cracked molar half ranch brand  \n",
       "30                                         thats girl  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "data['text'] = data['text'].str.lower()\n",
    "data['text'] = data['text'].apply(clean_all)\n",
    "# run time: around 3-4 minutes per 1 million texts\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "# prune empty texts\n",
    "data = data.dropna()\n",
    "data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15273740, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>birthyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356947</th>\n",
       "      <td>1981 first election become mayor burlington 10...</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356948</th>\n",
       "      <td>climate change single greatest threat facing p...</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356949</th>\n",
       "      <td>important amazon recognize workers rights stop...</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356950</th>\n",
       "      <td>america wealth income inequality major develop...</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356951</th>\n",
       "      <td>south join saturday #medicareforall rally rsvp</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  birthyear\n",
       "356947  1981 first election become mayor burlington 10...       1941\n",
       "356948  climate change single greatest threat facing p...       1941\n",
       "356949  important amazon recognize workers rights stop...       1941\n",
       "356950  america wealth income inequality major develop...       1941\n",
       "356951     south join saturday #medicareforall rally rsvp       1941"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data['birthyear'] == 1941\n",
    "y = data[x][['text','birthyear']]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder exists: C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\n",
      "['birthyear', 'fame', 'gender', 'occupation']\n",
      "birthyear\n",
      "[1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2007, 2008]\n",
      "folder exists: C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1940.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1941.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1942.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1943.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1944.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1945.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1946.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1947.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1948.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1949.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1950.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1951.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1952.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1953.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1954.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1955.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1956.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1957.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1958.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1959.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1960.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1961.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1962.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1963.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1964.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1965.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1966.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1967.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1968.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1969.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1970.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1971.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1972.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1973.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1974.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1975.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1976.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1977.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1978.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1979.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1980.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1981.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1982.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1983.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1984.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1985.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1986.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1987.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1988.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1989.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1990.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1991.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1992.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1993.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1994.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1995.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1996.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1997.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1998.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\1999.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\2000.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\2001.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\2002.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\2003.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\2004.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\2005.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\2007.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\birthyear\\2008.csv\n",
      "fame\n",
      "['star', 'superstar']\n",
      "folder exists: C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\fame\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\fame\\star.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\fame\\superstar.csv\n",
      "gender\n",
      "['female', 'male', 'nonbinary']\n",
      "folder exists: C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\gender\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\gender\\female.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\gender\\male.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\gender\\nonbinary.csv\n",
      "occupation\n",
      "['creator', 'manager', 'performer', 'politics', 'professional', 'religious', 'science', 'sports']\n",
      "folder exists: C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\occupation\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\occupation\\creator.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\occupation\\manager.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\occupation\\performer.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\occupation\\politics.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\occupation\\professional.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\occupation\\religious.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\occupation\\science.csv\n",
      "storing C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\single-label\\occupation\\sports.csv\n"
     ]
    }
   ],
   "source": [
    "def mkdir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    else:\n",
    "        print('folder exists: {}'.format(path))\n",
    "\n",
    "# the folder to hold the datasets (csv) with [text, label]\n",
    "single_label_dir = os.path.join(os.getcwd(), 'single-label')\n",
    "mkdir(single_label_dir)\n",
    "\n",
    "categories = list(data.columns.values)\n",
    "categories = categories[:-1]\n",
    "print(categories)\n",
    "\n",
    "for categ in categories:\n",
    "    print(categ)\n",
    "    vals = sorted(data[categ].unique())\n",
    "    print(vals)\n",
    "    # create a folder for each category\n",
    "    categ_path = os.path.join(single_label_dir, categ)\n",
    "    mkdir(categ_path)\n",
    "    # store each corresponding dataframe in respective category folders        \n",
    "    for val in vals:\n",
    "        #print('{}: {}'.format(val, type(val)))\n",
    "        condition = data[categ] == val\n",
    "        tmp_df = data[condition][['text', categ]]  # this extracts the text and column\n",
    "        save_path = categ_path + '\\\\' + str(val) + '.csv'\n",
    "        print('storing {}'.format(save_path))\n",
    "        tmp_df.to_csv(save_path)\n",
    "        del tmp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
