{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\SPLIT\\feed00.csv\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\SPLIT\\feed01.csv\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\SPLIT\\feed02.csv\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\SPLIT\\feed03.csv\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\SPLIT\\feed04.csv\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\SPLIT\\feed05.csv\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\SPLIT\\feed06.csv\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\SPLIT\\feed07.csv\n",
      "C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\SPLIT\\feed08.csv\n"
     ]
    }
   ],
   "source": [
    "df = None\n",
    "read_multiple = True\n",
    "if read_multiple:\n",
    "    import glob\n",
    "    samples = glob.glob(os.path.join(os.getcwd(), 'SPLIT') + '/*')\n",
    "    dfs = []\n",
    "    for sample in samples:\n",
    "        print(sample)\n",
    "        df = pd.read_csv(sample, names = ['id', 'text', 'birthyear', 'fame', 'gender', 'occupation'])\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    del dfs\n",
    "    df.reset_index()\n",
    "    df.to_csv('all_data_cleaned.csv')\n",
    "else:\n",
    "    df = pd.read_csv('all_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)  # shuffle it!\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squish the birthyears to a scale from 0->1\n",
    "birthyears = df.birthyear.unique()\n",
    "_min = min(birthyears)\n",
    "_max = max(birthyears)\n",
    "\n",
    "def normalize_birthyear(year):\n",
    "    return (year-_min)/(_max-_min)\n",
    "\n",
    "birthyear_labels = df.birthyear.apply(normalize_birthyear)\n",
    "birthyear_labels = birthyear_labels.values\n",
    "birthyear_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_onehot = ['fame', 'gender', 'occupation']\n",
    "\n",
    "labels = {}\n",
    "\n",
    "for label in labels_to_onehot:\n",
    "    unique_classes = len(df[label].unique())\n",
    "    print('{} unique classes in {}'.format(unique_classes, label))\n",
    "    labels_nd = df[label].values  # the values in the respective column\n",
    "    labels[label] = pd.get_dummies(labels_nd)  # one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fame_labels = labels['fame']\n",
    "gender_labels = labels['gender']\n",
    "occ_labels = labels['occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True\n",
    "tokenizer = None\n",
    "if load:\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "else:\n",
    "    from keras.preprocessing.text import Tokenizer\n",
    "    vocab_size = 15000\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=vocab_size)\n",
    "    tokenizer.fit_on_texts(df.text)\n",
    "    \n",
    "    # saving\n",
    "    with open('tokenizer.pickle', 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load:\n",
    "    with open('textmatrix.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "else:\n",
    "    X = tokenizer.texts_to_matrix(df.text, mode='tfidf')\n",
    "    with open('textmatrix.pickle', 'wb') as handle:\n",
    "        pickle.dump(X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# can safely delete df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = df.shape[0]\n",
    "test_size = int(num_items * 0.2)  # the amount of rows to use as validation set\n",
    "SIZE = num_items - test_size\n",
    "SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and validation set 80:20\n",
    "x_train, x_val = X[:SIZE], X[SIZE:]\n",
    "\n",
    "birthyear_train, birthyear_val = birthyear_labels[:SIZE], birthyear_labels[SIZE:]\n",
    "\n",
    "fame_train, fame_val = fame_labels[:SIZE], fame_labels[SIZE:]\n",
    "\n",
    "gender_train, gender_val = gender_labels[:SIZE], gender_labels[SIZE:]\n",
    "\n",
    "occ_train, occ_val = occ_labels[:SIZE], occ_labels[SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shape = (vocab_size,)\n",
    "input_layer = Input(shape)\n",
    "# before splitting categories\n",
    "hidden_layer = Dense(units=1024, activation='relu')(input_layer)\n",
    "\n",
    "dropout_layer = Dropout(0.3)(hidden_layer)\n",
    "\n",
    "branch_layer = Dense(units=512, activation='relu')(dropout_layer)\n",
    "# birthyear\n",
    "_ = Dense(units=128, activation='relu')(branch_layer)\n",
    "birthyear_out = Dense(units=1, activation='sigmoid', name='birthyear_out')(_)\n",
    "\n",
    "# fame\n",
    "_ = Dense(units=128, activation='relu')(branch_layer)\n",
    "fame_out = Dense(units=fame_labels.shape[1], activation='softmax', name='fame_out')(_)\n",
    "\n",
    "# gender\n",
    "_ = Dense(units=128, activation='relu')(branch_layer)\n",
    "gender_out = Dense(units=gender_labels.shape[1], activation='softmax', name='gender_out')(_)\n",
    "\n",
    "# occupation\n",
    "_ = Dense(units=128, activation='')(branch_layer)\n",
    "occ_out = Dense(units=occ_labels.shape[1], activation='softmax', name='occ_out')(_)\n",
    "\n",
    "model = Model(input=input_layer, outputs=[birthyear_out, fame_out, gender_out, occ_out])\n",
    "#model = Model(input=input_layer, outputs=fame_out)\n",
    "loss_fn = 'categorical_crossentropy'\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'birthyear_out': 'mse', 'fame_out': loss_fn, 'gender_out': loss_fn, 'occ_out': loss_fn},\n",
    "              metrics={'birthyear_out': 'mae', 'fame_out': 'accuracy', 'gender_out': 'accuracy', 'occ_out': 'accuracy'}\n",
    "             )\n",
    "\n",
    "#model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (vocab_size,)\n",
    "input_layer = Input(shape)\n",
    "\n",
    "out_activation = 'softmax'  # sigmoid/tanh/relu\n",
    "mid_activation = 'relu'\n",
    "\n",
    "# before splitting categories\n",
    "hidden_layer = Dense(units=1024, activation='relu')(input_layer)\n",
    "\n",
    "dropout_layer = Dropout(0.3)(hidden_layer)\n",
    "\n",
    "branch_layer = Dense(units=512, activation='selu')(dropout_layer)\n",
    "# birthyear\n",
    "_ = Dense(units=128, activation=mid_activation)(branch_layer)\n",
    "birthyear_out = Dense(units=1, activation='sigmoid', name='birthyear_out')(_)\n",
    "\n",
    "# fame\n",
    "_ = Dense(units=128, activation=mid_activation)(branch_layer)\n",
    "fame_out = Dense(units=fame_labels.shape[1], activation=out_activation, name='fame_out')(_)\n",
    "\n",
    "# gender\n",
    "_ = Dense(units=128, activation=mid_activation)(branch_layer)\n",
    "gender_out = Dense(units=gender_labels.shape[1], activation=out_activation, name='gender_out')(_)\n",
    "\n",
    "# occupation\n",
    "_ = Dense(units=128, activation=mid_activation)(branch_layer)\n",
    "occ_out = Dense(units=occ_labels.shape[1], activation=out_activation, name='occ_out')(_)\n",
    "\n",
    "model = Model(input=input_layer, outputs=[birthyear_out, fame_out, gender_out, occ_out])\n",
    "#model = Model(input=input_layer, outputs=fame_out)\n",
    "loss_fn = 'categorical_crossentropy'\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'birthyear_out': 'mse',\n",
    "                    'fame_out': loss_fn,\n",
    "                    'gender_out': loss_fn,\n",
    "                    'occ_out': loss_fn},\n",
    "              metrics={'birthyear_out': 'accuracy',\n",
    "                       'fame_out': 'accuracy',\n",
    "                       'gender_out': 'accuracy',\n",
    "                       'occ_out': 'accuracy'}\n",
    "             )\n",
    "\n",
    "#model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = keras.callbacks.TensorBoard(log_dir='./tensorboard/run7', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [birthyear_train, fame_train, gender_train, occ_train]\n",
    "start_epoch = 0\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=32, callbacks=[board], initial_epoch=start_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model-7epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_val, [birthyear_val, fame_val, gender_val, occ_val])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_user(model, user_vec, actual=None, verbose=False):\n",
    "    result = model.predict([[user_vec]])\n",
    "    fame = [\"rising\", \"star\", \"superstar\"]\n",
    "    gender = [\"female\", \"male\", \"nonbinary\"]\n",
    "    occupation = [\"creator\", \"manager\", \"performer\", \"politics\", \"professional\", \"religious\", \"science\", \"sports\"]\n",
    "\n",
    "    birth_pred = result[0][0][0]\n",
    "    fame_pred = result[1][0]\n",
    "    gender_pred = result[2][0]\n",
    "    occ_pred = result[3][0]\n",
    "    \n",
    "    errors = False  # check for errors on the fame/gender/occupation metrics\n",
    "    \n",
    "    year_pred = int(birth_pred * (_max - _min) + _min)\n",
    "    year_real = int(birthyear_val[actual] * (_max - _min) + _min)\n",
    "    \n",
    "    fame_pred = fame[fame_pred.argmax()]\n",
    "    fame_real = fame_val.iloc[actual].idxmax()\n",
    "    \n",
    "    gend_pred = gender[gender_pred.argmax()]\n",
    "    gend_real = gender_val.iloc[actual].idxmax()\n",
    "    \n",
    "    occu_pred = occupation[occ_pred.argmax()]\n",
    "    occu_real = occ_val.iloc[actual].idxmax()\n",
    "    \n",
    "    errors = [fame_pred != fame_real, gend_pred != gend_real, occu_pred != occu_real]\n",
    "\n",
    "    if verbose and sum(errors) != 0:  # only print wrong predictions!\n",
    "        #print(\"Predicted values (real ones in parentheses)\")\n",
    "        print('Birthyear:\\t{} ({})'.format(year_pred, year_real))\n",
    "        print('Fame status:\\t{} ({})'.format(fame_pred, fame_real))\n",
    "        print('Gender:   \\t{} ({})'.format(gend_pred, gend_real))\n",
    "        print('Occupation:\\t{} ({})'.format(occu_pred, occu_real))\n",
    "        # print some of the text...\n",
    "        print(\"--------------------------------------------\")\n",
    "        \n",
    "    return abs(year_pred - year_real), errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birthyear_errors = []\n",
    "errors = {'fame': 0, 'gender': 0, 'occupation': 0}\n",
    "# test_size\n",
    "tests = test_size\n",
    "for i in range(tests):\n",
    "    year_diff, error = predict_user(model, x_val[i], actual=i, verbose=True)\n",
    "    birthyear_errors.append(year_diff)\n",
    "    errors['fame'] += error[0]\n",
    "    errors['gender'] += error[1]\n",
    "    errors['occupation'] += error[2]\n",
    "    \n",
    "    \n",
    "print('Average off by {} years'.format(sum(birthyear_errors)/len(birthyear_errors)))\n",
    "print('Fame err: {}/{}'.format(errors['fame'], tests))\n",
    "print('Gender err: {}/{}'.format(errors['gender'], tests))\n",
    "print('Occupation err: {}/{}'.format(errors['occupation'], tests))\n",
    "\n",
    "# create object with which labels were misclassified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
