{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True  # if pickle models are saved or not!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "read_multiple = False\n",
    "if read_multiple:\n",
    "    import glob\n",
    "    samples = glob.glob(os.path.join(os.getcwd(), 'SPLIT') + '/*')\n",
    "    dfs = []\n",
    "    for sample in samples:\n",
    "        print(sample)\n",
    "        df = pd.read_csv(sample, names = ['id', 'text', 'birthyear', 'fame', 'gender', 'occupation'])\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    del dfs\n",
    "    df.reset_index()\n",
    "    df.to_csv('all_data_cleaned.csv')\n",
    "elif not load:  # skip if the pickled files are present\n",
    "    df = pd.read_csv('all_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df:\n",
    "    df = df.sample(frac=1)  # shuffle it!\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load:\n",
    "    with open('pickles/years.pickle', 'rb') as handle:\n",
    "        birthyear_labels = pickle.load(handle)\n",
    "else:\n",
    "    # squish the birthyears to a scale from 0->1\n",
    "    birthyears = df.birthyear.unique()\n",
    "    _min = min(birthyears)\n",
    "    _max = max(birthyears)\n",
    "\n",
    "    def normalize_birthyear(year):\n",
    "        return (year-_min)/(_max-_min)\n",
    "\n",
    "    birthyear_labels = df.birthyear.apply(normalize_birthyear)\n",
    "    birthyear_labels = birthyear_labels.values\n",
    "\n",
    "    with open('pickles/years.pickle', 'wb') as handle:\n",
    "        pickle.dump(birthyear_labels, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load:\n",
    "    with open('pickles/labels.pickle', 'rb') as handle:\n",
    "        labels = pickle.load(handle)\n",
    "else:\n",
    "    labels_to_onehot = ['fame', 'gender', 'occupation']\n",
    "    labels = {}\n",
    "\n",
    "    for label in labels_to_onehot:\n",
    "        unique_classes = len(df[label].unique())\n",
    "        print('{} unique classes in {}'.format(unique_classes, label))\n",
    "        labels_nd = df[label].values  # the values in the respective column\n",
    "        labels[label] = pd.get_dummies(labels_nd)  # one-hot\n",
    "    with open('pickles/labels.pickle', 'wb') as handle:\n",
    "        pickle.dump(labels, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "fame_labels = labels['fame']\n",
    "gender_labels = labels['gender']\n",
    "occ_labels = labels['occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = None\n",
    "vocab_size = 15000\n",
    "\n",
    "if load:\n",
    "    with open('pickles/tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "else:\n",
    "    from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=vocab_size)\n",
    "    tokenizer.fit_on_texts(df.text)\n",
    "    \n",
    "    # saving\n",
    "    with open('pickles/tokenizer.pickle', 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 15000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load:\n",
    "    with open('pickles/textmatrix.pickle', 'rb') as handle:\n",
    "        X = pickle.load(handle)\n",
    "else:\n",
    "    X = tokenizer.texts_to_matrix(df.text, mode='tfidf')\n",
    "    with open('pickles/textmatrix.pickle', 'wb') as handle:\n",
    "        pickle.dump(X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# can safely delete df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27061"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_items = birthyear_labels.shape[0]\n",
    "test_size = int(num_items * 0.2)  # the amount of rows to use as validation set\n",
    "SIZE = num_items - test_size\n",
    "SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and validation set 80:20\n",
    "x_train, x_val = X[:SIZE], X[SIZE:]\n",
    "\n",
    "birthyear_train, birthyear_val = birthyear_labels[:SIZE], birthyear_labels[SIZE:]\n",
    "\n",
    "fame_train, fame_val = fame_labels[:SIZE], fame_labels[SIZE:]\n",
    "\n",
    "gender_train, gender_val = gender_labels[:SIZE], gender_labels[SIZE:]\n",
    "\n",
    "occ_train, occ_val = occ_labels[:SIZE], occ_labels[SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 15000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         15361024    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          131200      dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          131200      dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          131200      dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          131200      dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "birthyear_out (Dense)           (None, 1)            129         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "fame_out (Dense)                (None, 3)            387         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender_out (Dense)              (None, 3)            387         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "occ_out (Dense)                 (None, 8)            1032        dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 16,937,359\n",
      "Trainable params: 16,937,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shape = (vocab_size,)\n",
    "input_layer = Input(shape)\n",
    "\n",
    "in_activation = 'relu'\n",
    "branch_activation = 'selu'\n",
    "mid_activation = 'relu'\n",
    "out_activation = 'softmax'  # sigmoid/tanh/relu\n",
    "\n",
    "year_activation = 'sigmoid'\n",
    "\n",
    "_year = 'birthyear_out'\n",
    "_fame = 'fame_out'\n",
    "_gend = 'gender_out'\n",
    "_occu = 'occ_out'\n",
    "\n",
    "\n",
    "INPUT_DIM = 1024\n",
    "DROPOUT = 0.3\n",
    "HIDDEN_DIM = 1024\n",
    "MID_DIM = 128\n",
    "\n",
    "loss_fn = 'categorical_crossentropy'\n",
    "\n",
    "# before splitting categories\n",
    "hidden_layer = Dense(units=INPUT_DIM, activation=in_activation)(input_layer)\n",
    "\n",
    "dropout_layer = Dropout(DROPOUT)(hidden_layer)\n",
    "\n",
    "branch_layer = Dense(units=HIDDEN_DIM, activation=in_activation)(dropout_layer)\n",
    "# birthyear\n",
    "_ = Dense(units=MID_DIM, activation=mid_activation)(branch_layer)\n",
    "birthyear_out = Dense(units=1, activation=year_activation, name=_year)(_)\n",
    "\n",
    "# fame\n",
    "_ = Dense(units=MID_DIM, activation=mid_activation)(branch_layer)\n",
    "fame_out = Dense(units=fame_labels.shape[1], activation=out_activation, name=_fame)(_)\n",
    "\n",
    "# gender\n",
    "_ = Dense(units=MID_DIM, activation=mid_activation)(branch_layer)\n",
    "gender_out = Dense(units=gender_labels.shape[1], activation=out_activation, name=_gend)(_)\n",
    "\n",
    "# occupation\n",
    "_ = Dense(units=MID_DIM, activation=mid_activation)(branch_layer)\n",
    "occ_out = Dense(units=occ_labels.shape[1], activation=out_activation, name=_occu)(_)\n",
    "\n",
    "OUTPUTS = [birthyear_out, fame_out, gender_out, occ_out]\n",
    "model = Model(\n",
    "    inputs=input_layer,\n",
    "    outputs=OUTPUTS)\n",
    "#model = Model(input=input_layer, outputs=fame_out)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={\n",
    "                _year: 'mse',\n",
    "                _fame: loss_fn,\n",
    "                _gend: loss_fn,\n",
    "                _occu: loss_fn},\n",
    "              loss_weights={\n",
    "                _year: 1.2,\n",
    "                _fame: 1.1,\n",
    "                _gend: 1.0,\n",
    "                _occu: 1.2},\n",
    "              metrics={\n",
    "                'birthyear_out': 'mae',\n",
    "                'fame_out': 'accuracy',\n",
    "                'gender_out': 'accuracy',\n",
    "                'occ_out': 'accuracy'}\n",
    "             )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = keras.callbacks.TensorBoard(log_dir='./tensorboard/final_run-10241024-20epoch', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "MIN_CHANGE_REQUIRED = 0  # change in values between epochs\n",
    "EPOCHS_TO_WAIT = 2\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                          patience=EPOCHS_TO_WAIT,\n",
    "                                          baseline=None,\n",
    "                                          restore_best_weights=False)\n",
    "\n",
    "chkpt = keras.callbacks.ModelCheckpoint(filepath='models/best_model.h5', monitor='occ_out_loss', save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "27061/27061 [==============================] - 26s 957us/step - loss: 2.5962 - birthyear_out_loss: 0.0394 - fame_out_loss: 0.7808 - gender_out_loss: 0.4023 - occ_out_loss: 1.0731 - birthyear_out_mean_absolute_error: 0.1490 - fame_out_acc: 0.7415 - gender_out_acc: 0.8580 - occ_out_acc: 0.70885s - loss: 2.7864 - birthyear_out_loss: 0.0433 - fame_out_loss: 0.8463 - gender_out_loss: 0.4395 - occ_out_loss: 1.1366 - birthyear_out_\n",
      "Epoch 2/20\n",
      "27061/27061 [==============================] - 25s 930us/step - loss: 1.6866 - birthyear_out_loss: 0.0250 - fame_out_loss: 0.5003 - gender_out_loss: 0.2066 - occ_out_loss: 0.7497 - birthyear_out_mean_absolute_error: 0.1221 - fame_out_acc: 0.7880 - gender_out_acc: 0.9181 - occ_out_acc: 0.758913s - loss: 1.7461 - birthyear_out_loss: 0.0259 - fame_out_los - ETA: 7s - loss: 1.7165 - birthyear_out_loss: 0.0254 - fame_out_loss: 0.5061 - gender_out_loss: 0.2112 - occ_out_loss: 0.7651 - birthyear_out_mean_absolute_error: 0.1232 - fa - ETA: 3s - loss: 1.7055 - birthyear_out_loss: 0.0253 - fame_out_loss: 0.5036 - gender_out_loss: 0.2081 - occ_out_loss: 0.7609 - birthyear_out_mean_absolute_error: 0.1228 - fame_out_acc: 0.7871 - gender_out_acc: 0.9174 - oc - ETA: 2s - loss: 1.7009 - birthyear_out_loss: 0.0252 - fame_out_loss: 0.5034 - gender_out_loss: 0.2085 - occ_out_loss: 0.7570 - birthyear_out_mean_absolute_error: 0.1225 - fame_out_acc: 0.78\n",
      "Epoch 3/20\n",
      "27061/27061 [==============================] - 26s 944us/step - loss: 1.4411 - birthyear_out_loss: 0.0239 - fame_out_loss: 0.4182 - gender_out_loss: 0.1606 - occ_out_loss: 0.6598 - birthyear_out_mean_absolute_error: 0.1191 - fame_out_acc: 0.8210 - gender_out_acc: 0.9391 - occ_out_acc: 0.7837ETA: 6s - loss: 1.4342 - birthyear_out_loss: 0.0239 - fame_out_loss: 0.4181 - gender_out_loss: 0.1602 - occ_out_loss: 0.6545 - birthyear_out_mean_absolute_error: 0.1191 - fame_out_acc: 0.8204 - gender_out_acc: 0.9388 - occ_out_acc: 0. - ETA: 6s - loss: 1.4356 - birthyear_out_loss: 0.0239 - fame_out_loss: 0.4175 - gender_out_loss: 0.1611 - occ_out_loss: 0.6555 - birthyear_out_mean_absolute_error: 0.1192 - fame_out_acc: 0.8207 - gender_o - ETA: 4s - loss: 1.4372 - birthyear_out_loss: 0.0239 - fame_out_loss: 0.4181 - gender_out_loss: 0.1604 - occ_out_loss: 0.6568 - birthyear_out_mean_absolute_error: 0.1192 - fame_out_acc: 0.8205 - gender_out_acc: 0.9389 - occ - ETA: 3s - loss: 1.4392 - birthyear_out_loss: 0.0239 - fame_out_loss: 0.4186 - gender_out_loss: 0.1593 - occ_out_loss: 0.6590 - birthyear_out_mean_absolute_error: 0.1192 - fame_out_acc\n",
      "Epoch 4/20\n",
      "27061/27061 [==============================] - 26s 947us/step - loss: 1.2334 - birthyear_out_loss: 0.0236 - fame_out_loss: 0.3497 - gender_out_loss: 0.1257 - occ_out_loss: 0.5789 - birthyear_out_mean_absolute_error: 0.1186 - fame_out_acc: 0.8563 - gender_out_acc: 0.9525 - occ_out_acc: 0.809518s - loss: 1.1822 - birthyear_out_loss: 0.0232 - fame_out_loss: 0.3429 - gender_out_loss: 0.1145  - ETA: 4s - loss: 1.2271 - birthyear_out_loss: 0.0236 - fame_out_loss: 0.3508 - gender_out_loss: 0.1251 - occ_out_loss: 0.5731 - birthyear_out_mean_absolute_err\n",
      "Epoch 5/20\n",
      "27061/27061 [==============================] - 26s 949us/step - loss: 1.0707 - birthyear_out_loss: 0.0231 - fame_out_loss: 0.2957 - gender_out_loss: 0.1066 - occ_out_loss: 0.5093 - birthyear_out_mean_absolute_error: 0.1172 - fame_out_acc: 0.8806 - gender_out_acc: 0.9605 - occ_out_acc: 0.83218s - loss: 1.0683 - birthyear_out_loss: 0.0233 - fame_out_loss: 0.2937 - gender_out_loss: \n",
      "Epoch 6/20\n",
      "27061/27061 [==============================] - 26s 955us/step - loss: 0.9317 - birthyear_out_loss: 0.0228 - fame_out_loss: 0.2483 - gender_out_loss: 0.0960 - occ_out_loss: 0.4460 - birthyear_out_mean_absolute_error: 0.1161 - fame_out_acc: 0.9019 - gender_out_acc: 0.9633 - occ_out_acc: 0.85069s - loss: 0.9248 - birthyear_out_loss: 0.0228 - fame_out_loss: 0.2460 - gender_out_loss: 0.0940 - occ_out_loss: 0.4439 - birthyear_out_mean_absolute_error: 0.1161 - fame_out_acc: 0.9025 - gender_out_acc: 0.964 - ETA: 8s - loss: 0.9194 - birthyear_out_loss: 0.0228 - fame_out_loss: 0.2441 - gender_out_loss: 0.0934 - occ_out_loss: 0.4419 - birthyear_out_mean_absolute_error: 0.1161 - fame_out_ac - ETA: 4s - loss: 0.9271 - birthyear_out_loss: 0.0228 - fame_out_loss: 0.2461 - gender_out_loss: 0.0942 - occ_out_loss: 0.4457 - birthyear_out_mean_absolute_e\n",
      "Epoch 7/20\n",
      "27061/27061 [==============================] - 24s 884us/step - loss: 0.8317 - birthyear_out_loss: 0.0225 - fame_out_loss: 0.2170 - gender_out_loss: 0.0855 - occ_out_loss: 0.4005 - birthyear_out_mean_absolute_error: 0.1151 - fame_out_acc: 0.9144 - gender_out_acc: 0.9685 - occ_out_acc: 0.866222s - loss: 0.7556 - birthyear_out_loss: 0.0226 - fame - ETA: 15s - loss: 0.7922 - birthyear_out_loss: 0.0223 - fame_out_loss: 0.2 - ETA: 10s - loss: 0.8074 - birthyear_out_loss: 0.022\n",
      "Epoch 8/20\n",
      "27061/27061 [==============================] - 26s 962us/step - loss: 0.7242 - birthyear_out_loss: 0.0223 - fame_out_loss: 0.1834 - gender_out_loss: 0.0777 - occ_out_loss: 0.3484 - birthyear_out_mean_absolute_error: 0.1144 - fame_out_acc: 0.9264 - gender_out_acc: 0.9715 - occ_out_acc: 0.885314s - loss: 0.6945 - birthyear_out_loss: 0.0219 - fame_out_loss: 0.1745 - gender_out_loss: 0.0726 - occ_out_loss: 0.3364 - birthyear_out_mean_absolu - ETA: 12s - loss: 0.6980 - birthyear_out_loss: 0.0219 - fame_out_loss: 0.1770 - gender_out_loss: 0.0730 - occ_out_loss: 0.3366 - birthyear_out_mean_absolute_error: 0.1134 - fame_out_acc: 0.9298 -  - ETA: 10s - loss: 0.6965 - birthyear_out_loss: 0.0219 - fame_out_loss: 0.1758 - gender_out_loss: 0.0723 - occ_out_loss: 0.3371 - birthyear_out_mean_absolute_error: - ETA: 7s - loss: 0.7013 - birthyear_out_loss: 0.0221 - fame_out_loss: 0.1761 - gender_out_loss: 0.0743 - occ_out_loss: 0.339\n",
      "Epoch 9/20\n",
      "27061/27061 [==============================] - 26s 952us/step - loss: 0.6623 - birthyear_out_loss: 0.0219 - fame_out_loss: 0.1665 - gender_out_loss: 0.0733 - occ_out_loss: 0.3164 - birthyear_out_mean_absolute_error: 0.1132 - fame_out_acc: 0.9360 - gender_out_acc: 0.9739 - occ_out_acc: 0.89600s - loss: 0.6626 - birthyear_out_loss: 0.0218 - fame_out_loss: 0.1668 - gender_out_loss: 0.0734 - occ_out_loss: 0.3163 - birthyear_out_mean_absolute_error: 0.1131 - fame_out_acc: 0.9359 - gender_out_acc: 0.9739 - occ_out_ac\n",
      "Epoch 10/20\n",
      "27061/27061 [==============================] - 26s 956us/step - loss: 0.6033 - birthyear_out_loss: 0.0219 - fame_out_loss: 0.1484 - gender_out_loss: 0.0689 - occ_out_loss: 0.2874 - birthyear_out_mean_absolute_error: 0.1136 - fame_out_acc: 0.9447 - gender_out_acc: 0.9760 - occ_out_acc: 0.904824s - loss: 0.5734 - birthyear_out_loss: 0.0214 - fame_out_loss: 0.1176 - gender_out_loss: 0 - ETA: 13s - loss: 0.5961 - birthyear_out_loss: 0.0215 - fame_out_loss: 0.1416 - gender_out_loss: 0.0707 - occ_out_loss:  - ETA: 9s - loss: 0.5966 - birthyear_out_loss: 0.0215 - fame_out_loss: 0.1458 - gender_out_loss: 0.0708 - occ_out_loss: 0.2830 - birthyear_out_mean_absolute_error: 0.1123 - fame_out_acc: 0.9456 - gender_out_acc: 0.9759 - occ_out_ac - ETA: 9s - loss: 0.5957 - birthyear_out_loss: 0.0216 - fame_out_loss: 0.1455 - gender_out_\n",
      "Epoch 11/20\n",
      "27061/27061 [==============================] - 26s 963us/step - loss: 0.5479 - birthyear_out_loss: 0.0217 - fame_out_loss: 0.1347 - gender_out_loss: 0.0637 - occ_out_loss: 0.2584 - birthyear_out_mean_absolute_error: 0.1129 - fame_out_acc: 0.9502 - gender_out_acc: 0.9779 - occ_out_acc: 0.91414s - loss: 0.5437 - birthyear_out_loss: 0.0217 - fame_out_loss: 0.1325 - gender_out_loss: 0.0637 - occ_out_loss: 0.2569 - birthyear_out_mean_absolute_error: 0.1128 \n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27061/27061 [==============================] - 25s 930us/step - loss: 0.5098 - birthyear_out_loss: 0.0214 - fame_out_loss: 0.1229 - gender_out_loss: 0.0583 - occ_out_loss: 0.2422 - birthyear_out_mean_absolute_error: 0.1117 - fame_out_acc: 0.9557 - gender_out_acc: 0.9805 - occ_out_acc: 0.9210ETA: 8s - loss: 0.4944 - birthyear_out_loss: 0.0215 - fame_out_loss: 0.1174 - gender_out_loss: 0.0562 - occ_out_loss: 0.2361 - birthyear_out_mean_absolute_error: 0.1120 - fam - ETA: 4s - loss: 0.4963 - birthyear_out_loss: 0.0215 - fame_out_loss: 0.1163 - gender_out_loss: 0.0546 - occ_out_loss: 0.2400 - birthyear_out_mean_absolute_\n",
      "Epoch 13/20\n",
      "27061/27061 [==============================] - 26s 944us/step - loss: 0.4633 - birthyear_out_loss: 0.0213 - fame_out_loss: 0.1120 - gender_out_loss: 0.0542 - occ_out_loss: 0.2169 - birthyear_out_mean_absolute_error: 0.1118 - fame_out_acc: 0.9603 - gender_out_acc: 0.9822 - occ_out_acc: 0.92951s - loss: 0.4643 - birthyear_out_loss: 0.0213 - fame_out_loss: 0.1118 - gender_out_loss: 0.0546 - occ_out_loss: 0.2176 - birthyear_out_mean_absolute_error: 0.1118 - fame_out_acc: 0.9603 - gender_out_acc: 0.9822 -\n",
      "Epoch 14/20\n",
      "27061/27061 [==============================] - 25s 935us/step - loss: 0.4482 - birthyear_out_loss: 0.0208 - fame_out_loss: 0.1149 - gender_out_loss: 0.0489 - occ_out_loss: 0.2067 - birthyear_out_mean_absolute_error: 0.1101 - fame_out_acc: 0.9601 - gender_out_acc: 0.9822 - occ_out_acc: 0.932023s - loss: 0.3980 - birthyear_out_loss: 0.0209 - fame_out_loss: 0.1035 - gender_out_loss: 0.044 - ETA: 19s - loss: 0.39 - ETA: 13s - loss: 0.4300 - birthyear_out_loss:  - ETA: 4s - loss: 0.4488 - birthyear_out_loss: 0.0210 - fame_out_loss: 0.1129 - gender_out_loss: 0.0488 - occ_out_loss: 0.2089 - birthyear_out_mean_absolute_erro\n",
      "Epoch 15/20\n",
      "27061/27061 [==============================] - 22s 831us/step - loss: 0.4338 - birthyear_out_loss: 0.0206 - fame_out_loss: 0.1059 - gender_out_loss: 0.0501 - occ_out_loss: 0.2021 - birthyear_out_mean_absolute_error: 0.1090 - fame_out_acc: 0.9621 - gender_out_acc: 0.9829 - occ_out_acc: 0.9357\n",
      "Epoch 16/20\n",
      "27061/27061 [==============================] - 23s 845us/step - loss: 0.4059 - birthyear_out_loss: 0.0204 - fame_out_loss: 0.0972 - gender_out_loss: 0.0511 - occ_out_loss: 0.1862 - birthyear_out_mean_absolute_error: 0.1085 - fame_out_acc: 0.9651 - gender_out_acc: 0.9823 - occ_out_acc: 0.9393\n",
      "Epoch 17/20\n",
      "27061/27061 [==============================] - 26s 949us/step - loss: 0.3737 - birthyear_out_loss: 0.0201 - fame_out_loss: 0.0932 - gender_out_loss: 0.0415 - occ_out_loss: 0.1713 - birthyear_out_mean_absolute_error: 0.1079 - fame_out_acc: 0.9678 - gender_out_acc: 0.9867 - occ_out_acc: 0.944224s - loss: 0.3870 - birthyear_out_loss: 0.0204 - fame_out_loss: 0.0854 - gender_out_loss: 0.0431 - occ_out_loss: 0.1879 - birthyear_out_mean_absolute_error: 0.1083 - fame_out_acc: 0.9670 - gender_out - ETA: 22s - loss: 0.3756 - birthyear_out_loss: 0.0198 - fame_out_loss: 0.0890 - gender_out_loss: 0.0409 - occ_out_lo - ETA: 10s - loss: 0.3652 - birthyear_out_loss: 0.0201 - fame_out_loss: 0.0884 - gender_out_loss: 0.0396 - occ_out_loss: 0.1702 - birthyear_out_mean_absolute_error: 0.1079 - fame_out_ac - ETA: 8s - loss: 0.3705 - birthyear_out_loss: 0.0201 - fame_out_loss: 0.0913 - gender_out_loss: 0.0415 - occ_out_loss: 0.1704 - birthyear_out_mean_absolute_error: 0.1081 - fam - ETA: 4s - loss: 0.3704 - birthyear_out_loss: 0.0201 - fame_out_loss: 0.0924 - gender_out_loss: 0.0403 - occ_out_loss: 0.1703 - birthyear_out_mean_absolute_error: 0.\n",
      "Epoch 18/20\n",
      "27061/27061 [==============================] - 25s 928us/step - loss: 0.3600 - birthyear_out_loss: 0.0198 - fame_out_loss: 0.0832 - gender_out_loss: 0.0440 - occ_out_loss: 0.1672 - birthyear_out_mean_absolute_error: 0.1069 - fame_out_acc: 0.9707 - gender_out_acc: 0.9860 - occ_out_acc: 0.947018s - loss: 0.3594 - birthyear_out_loss: 0.0196 - fame_out_loss: 0.0814 - gender_out_loss: 0.0506 - occ_out_loss: 0.1631 - birthyear_out_mean_absolute_error: 0.1056 - f - ETA: 16s - loss: 0.3530 - birthyear_out_loss: 0.0197 - fame_out_loss: 0 - ETA\n",
      "Epoch 19/20\n",
      "27061/27061 [==============================] - 25s 929us/step - loss: 0.3528 - birthyear_out_loss: 0.0201 - fame_out_loss: 0.0861 - gender_out_loss: 0.0440 - occ_out_loss: 0.1583 - birthyear_out_mean_absolute_error: 0.1078 - fame_out_acc: 0.9711 - gender_out_acc: 0.9848 - occ_out_acc: 0.950723s - loss: 0.3738 - birthyear_out_loss: 0.0201 - fame_out_loss: 0.0896 - gender_out_loss: 0.0458 - occ_out_loss: 0.1711 - birthyear_out_mean_abso - ETA: 20s - loss: 0.3384 - birthyear_out_loss: 0.0200 - fame_out_loss: 0.0854 - gender_out_loss: 0.0420 - occ_out_loss: 0.1487 - birthyear_out_mean_absolute_error: 0.1083 - fame_out_acc: 0.972 - ETA: 18s - loss: 0.3325 - birthyear_out_loss: 0.0203 - fame_out_loss: 0.0818 - gender_out_loss: 0.0393 - occ_out_loss: 0.1491 - birthyear_out_mean_absolute_error: 0. -  - ETA: 9s - loss: 0.3518 - birthyear_out_loss: 0.0199 - fame_out_loss: 0.0857 - gender_out_loss: 0.0429 - occ_out_loss: 0.1590 - birthyear_out_mean_absolute_error: 0.1075 - fame_out_acc: 0. - ETA: 6s - loss: 0.3493 - birthyear_out_loss: 0.0199 - fame_out_loss: 0.0860 - gender_out_loss: 0.0416 - occ_out_loss: 0.1577 - birthyear_out_mean_absolute_error: 0.1075 - fame_out_ac - ETA: 3s - loss: 0.3527 - birthyear_out_loss: 0.0199 - fame_out_loss: 0.0873 - gender_out_loss: 0.0441 - occ_out_loss: 0.1572 - birthyear_out_mean_absolute_error: 0.1074 - fame_out_acc: 0\n",
      "Epoch 20/20\n",
      "27061/27061 [==============================] - 25s 936us/step - loss: 0.3376 - birthyear_out_loss: 0.0196 - fame_out_loss: 0.0777 - gender_out_loss: 0.0421 - occ_out_loss: 0.1554 - birthyear_out_mean_absolute_error: 0.1066 - fame_out_acc: 0.9730 - gender_out_acc: 0.9861 - occ_out_acc: 0.951719s - loss: 0.3024 - birthyear_o - ETA: 3s - loss: 0.3392 - birthyear_out_loss: 0.0198 - fame_out_loss: 0.0767 - gender_out_loss: 0.0400 - occ_out_loss: 0.1593 - birthyear_out_mean_absolute_error: 0.1068 - fame_out_acc: 0.9736 - gender_out_acc: 0.9862 - occ_out_a - ETA: 2s - loss: 0.3380 - birthyear_out_loss: 0.0197 - fame_out_loss: 0.0772 - gender_out_loss: 0.0396 - occ_out_loss: 0.1582 - birthyear_out_mean_absolute_error: 0.1067 - fame_out_acc: 0.9734 - gen\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21d43d57ef0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = [birthyear_train, fame_train, gender_train, occ_train]\n",
    "start_epoch = 0\n",
    "end_epoch = 20\n",
    "bs = 32\n",
    "split_fac = 0\n",
    "callbacks = [board, chkpt]\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=end_epoch,\n",
    "          batch_size=bs,\n",
    "          callbacks=callbacks,\n",
    "          initial_epoch=start_epoch,\n",
    "          validation_split=split_fac,\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"30dropout20epoch.h5\"\n",
    "model.save('models/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 'best_model.h5'\n",
    "model_path = os.path.join(os.getcwd(), 'models', model_name)\n",
    "model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6765/6765 [==============================] - 1s 216us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.511419535881488,\n",
       " 0.02292521317287762,\n",
       " 0.7253973483774985,\n",
       " 0.2415108367618991,\n",
       " 1.1111241524120832,\n",
       " 0.11554673995495018,\n",
       " 0.8048780487981093,\n",
       " 0.9401330377028241,\n",
       " 0.7679231338032245]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(x_val, [birthyear_val, fame_val, gender_val, occ_val])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_min = 1940\n",
    "_max = 2008\n",
    "def predict_user(model, user_vec, actual=None, verbose=False):\n",
    "    result = model.predict([[user_vec]])\n",
    "    fame = [\"rising\", \"star\", \"superstar\"]\n",
    "    gender = [\"female\", \"male\", \"nonbinary\"]\n",
    "    occupation = [\"creator\", \"manager\", \"performer\", \"politics\", \"professional\", \"religious\", \"science\", \"sports\"]\n",
    "\n",
    "    birth_pred = result[0][0][0]\n",
    "    fame_pred = result[1][0]\n",
    "    gender_pred = result[2][0]\n",
    "    occ_pred = result[3][0]\n",
    "    \n",
    "    errors = False  # check for errors on the fame/gender/occupation metrics\n",
    "    \n",
    "    year_pred = int(birth_pred * (_max - _min) + _min)\n",
    "    year_real = int(birthyear_val[actual] * (_max - _min) + _min)\n",
    "    \n",
    "    fame_pred = fame[fame_pred.argmax()]\n",
    "    fame_real = fame_val.iloc[actual].idxmax()\n",
    "    \n",
    "    gend_pred = gender[gender_pred.argmax()]\n",
    "    gend_real = gender_val.iloc[actual].idxmax()\n",
    "    \n",
    "    occu_pred = occupation[occ_pred.argmax()]\n",
    "    occu_real = occ_val.iloc[actual].idxmax()\n",
    "    \n",
    "    errors = [fame_pred != fame_real, gend_pred != gend_real, occu_pred != occu_real]\n",
    "\n",
    "    if verbose and sum(errors) != 0:  # only print wrong predictions!\n",
    "        #print(\"Predicted values (real ones in parentheses)\")\n",
    "        print('Birthyear:\\t{} ({})'.format(year_pred, year_real))\n",
    "        print('Fame status:\\t{} ({})'.format(fame_pred, fame_real))\n",
    "        print('Gender:   \\t{} ({})'.format(gend_pred, gend_real))\n",
    "        print('Occupation:\\t{} ({})'.format(occu_pred, occu_real))\n",
    "        # print some of the text...\n",
    "        print(\"--------------------------------------------\")\n",
    "        \n",
    "    return abs(year_pred - year_real), errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average off by 7.844198078344419 years\n",
      "Fame err: 1320/6765\n",
      "Gender err: 405/6765\n",
      "Occupation err: 1570/6765\n"
     ]
    }
   ],
   "source": [
    "birthyear_errors = []\n",
    "errors = {'fame': 0, 'gender': 0, 'occupation': 0}\n",
    "# test_size\n",
    "tests = test_size\n",
    "for i in range(tests):\n",
    "    year_diff, error = predict_user(model, x_val[i], actual=i, verbose=False)\n",
    "    birthyear_errors.append(year_diff)\n",
    "    errors['fame'] += error[0]\n",
    "    errors['gender'] += error[1]\n",
    "    errors['occupation'] += error[2]\n",
    "    \n",
    "    \n",
    "print('Average off by {} years'.format(sum(birthyear_errors)/len(birthyear_errors)))\n",
    "print('Fame err: {}/{}'.format(errors['fame'], tests))\n",
    "print('Gender err: {}/{}'.format(errors['gender'], tests))\n",
    "print('Occupation err: {}/{}'.format(errors['occupation'], tests))\n",
    "\n",
    "# create object with which labels were misclassified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
