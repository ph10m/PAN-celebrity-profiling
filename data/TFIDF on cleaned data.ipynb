{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True  # if pickle models are saved or not!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "read_multiple = False\n",
    "if read_multiple:\n",
    "    import glob\n",
    "    samples = glob.glob(os.path.join(os.getcwd(), 'SPLIT') + '/*')\n",
    "    dfs = []\n",
    "    for sample in samples:\n",
    "        print(sample)\n",
    "        df = pd.read_csv(sample, names = ['id', 'text', 'birthyear', 'fame', 'gender', 'occupation'])\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    del dfs\n",
    "    df.reset_index()\n",
    "    df.to_csv('all_data_cleaned.csv')\n",
    "elif not load:  # skip if the pickled files are present\n",
    "    df = pd.read_csv('all_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df:\n",
    "    df = df.sample(frac=1)  # shuffle it!\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load:\n",
    "    with open('pickles/years.pickle', 'rb') as handle:\n",
    "        birthyear_labels = pickle.load(handle)\n",
    "else:\n",
    "    # squish the birthyears to a scale from 0->1\n",
    "    birthyears = df.birthyear.unique()\n",
    "    _min = min(birthyears)\n",
    "    _max = max(birthyears)\n",
    "\n",
    "    def normalize_birthyear(year):\n",
    "        return (year-_min)/(_max-_min)\n",
    "\n",
    "    birthyear_labels = df.birthyear.apply(normalize_birthyear)\n",
    "    birthyear_labels = birthyear_labels.values\n",
    "\n",
    "    with open('pickles/years.pickle', 'wb') as handle:\n",
    "        pickle.dump(birthyear_labels, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load:\n",
    "    with open('pickles/labels.pickle', 'rb') as handle:\n",
    "        labels = pickle.load(handle)\n",
    "else:\n",
    "    labels_to_onehot = ['fame', 'gender', 'occupation']\n",
    "    labels = {}\n",
    "\n",
    "    for label in labels_to_onehot:\n",
    "        unique_classes = len(df[label].unique())\n",
    "        print('{} unique classes in {}'.format(unique_classes, label))\n",
    "        labels_nd = df[label].values  # the values in the respective column\n",
    "        labels[label] = pd.get_dummies(labels_nd)  # one-hot\n",
    "    with open('pickles/labels.pickle', 'wb') as handle:\n",
    "        pickle.dump(labels, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "fame_labels = labels['fame']\n",
    "gender_labels = labels['gender']\n",
    "occ_labels = labels['occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = None\n",
    "vocab_size = 15000\n",
    "\n",
    "if load:\n",
    "    with open('pickles/tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "else:\n",
    "    from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=vocab_size)\n",
    "    tokenizer.fit_on_texts(df.text)\n",
    "    \n",
    "    # saving\n",
    "    with open('pickles/tokenizer.pickle', 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 15000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load:\n",
    "    with open('pickles/textmatrix.pickle', 'rb') as handle:\n",
    "        X = pickle.load(handle)\n",
    "else:\n",
    "    X = tokenizer.texts_to_matrix(df.text, mode='tfidf')\n",
    "    with open('pickles/textmatrix.pickle', 'wb') as handle:\n",
    "        pickle.dump(X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# can safely delete df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27061"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_items = birthyear_labels.shape[0]\n",
    "test_size = int(num_items * 0.2)  # the amount of rows to use as validation set\n",
    "SIZE = num_items - test_size\n",
    "SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and validation set 80:20\n",
    "x_train, x_val = X[:SIZE], X[SIZE:]\n",
    "\n",
    "birthyear_train, birthyear_val = birthyear_labels[:SIZE], birthyear_labels[SIZE:]\n",
    "\n",
    "fame_train, fame_val = fame_labels[:SIZE], fame_labels[SIZE:]\n",
    "\n",
    "gender_train, gender_val = gender_labels[:SIZE], gender_labels[SIZE:]\n",
    "\n",
    "occ_train, occ_val = occ_labels[:SIZE], occ_labels[SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 15000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 1024)         15361024    input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 512)          524800      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 128)          65664       dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 128)          65664       dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 128)          65664       dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 128)          65664       dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "birthyear_out (Dense)           (None, 1)            129         dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fame_out (Dense)                (None, 3)            387         dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gender_out (Dense)              (None, 3)            387         dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "occ_out (Dense)                 (None, 8)            1032        dense_30[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 16,150,415\n",
      "Trainable params: 16,150,415\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shape = (vocab_size,)\n",
    "input_layer = Input(shape)\n",
    "\n",
    "in_activation = 'relu'\n",
    "branch_activation = 'selu'\n",
    "mid_activation = 'relu'\n",
    "out_activation = 'softmax'  # sigmoid/tanh/relu\n",
    "\n",
    "year_activation = 'sigmoid'\n",
    "\n",
    "_year = 'birthyear_out'\n",
    "_fame = 'fame_out'\n",
    "_gend = 'gender_out'\n",
    "_occu = 'occ_out'\n",
    "\n",
    "\n",
    "INPUT_DIM = 1024\n",
    "DROPOUT = 0.6\n",
    "HIDDEN_DIM = 512\n",
    "MID_DIM = 128\n",
    "\n",
    "loss_fn = 'categorical_crossentropy'\n",
    "\n",
    "# before splitting categories\n",
    "hidden_layer = Dense(units=INPUT_DIM, activation=in_activation)(input_layer)\n",
    "\n",
    "dropout_layer = Dropout(DROPOUT)(hidden_layer)\n",
    "\n",
    "branch_layer = Dense(units=HIDDEN_DIM, activation=in_activation)(dropout_layer)\n",
    "# birthyear\n",
    "_ = Dense(units=MID_DIM, activation=mid_activation)(branch_layer)\n",
    "birthyear_out = Dense(units=1, activation=year_activation, name=_year)(_)\n",
    "\n",
    "# fame\n",
    "_ = Dense(units=MID_DIM, activation=mid_activation)(branch_layer)\n",
    "fame_out = Dense(units=fame_labels.shape[1], activation=out_activation, name=_fame)(_)\n",
    "\n",
    "# gender\n",
    "_ = Dense(units=MID_DIM, activation=mid_activation)(branch_layer)\n",
    "gender_out = Dense(units=gender_labels.shape[1], activation=out_activation, name=_gend)(_)\n",
    "\n",
    "# occupation\n",
    "_ = Dense(units=MID_DIM, activation=mid_activation)(branch_layer)\n",
    "occ_out = Dense(units=occ_labels.shape[1], activation=out_activation, name=_occu)(_)\n",
    "\n",
    "OUTPUTS = [birthyear_out, fame_out, gender_out, occ_out]\n",
    "model = Model(\n",
    "    inputs=input_layer,\n",
    "    outputs=OUTPUTS)\n",
    "#model = Model(input=input_layer, outputs=fame_out)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={\n",
    "                _year: 'mse',\n",
    "                _fame: loss_fn,\n",
    "                _gend: loss_fn,\n",
    "                _occu: loss_fn},\n",
    "              loss_weights={\n",
    "                _year: 1.8,\n",
    "                _fame: 1.0,\n",
    "                _gend: 1.0,\n",
    "                _occu: 1.5},\n",
    "              metrics={\n",
    "                'birthyear_out': 'mae',\n",
    "                'fame_out': 'accuracy',\n",
    "                'gender_out': 'accuracy',\n",
    "                'occ_out': 'accuracy'}\n",
    "             )\n",
    "\n",
    "#model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = keras.callbacks.TensorBoard(log_dir='./tensorboard/final_run-1', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "MIN_CHANGE_REQUIRED = 0  # change in values between epochs\n",
    "EPOCHS_TO_WAIT = 2\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                          patience=EPOCHS_TO_WAIT,\n",
    "                                          baseline=None,\n",
    "                                          restore_best_weights=False)\n",
    "\n",
    "chkpt = keras.callbacks.ModelCheckpoint(filepath='models/best_model.h5', monitor='val_loss', save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24354 samples, validate on 2707 samples\n",
      "Epoch 1/30\n",
      "24354/24354 [==============================] - 22s 890us/step - loss: 3.3571 - birthyear_out_loss: 0.0520 - fame_out_loss: 0.7794 - gender_out_loss: 0.5826 - occ_out_loss: 1.2677 - birthyear_out_mean_absolute_error: 0.1739 - fame_out_acc: 0.7335 - gender_out_acc: 0.7985 - occ_out_acc: 0.6700 - val_loss: 2.3132 - val_birthyear_out_loss: 0.0273 - val_fame_out_loss: 0.6198 - val_gender_out_loss: 0.2879 - val_occ_out_loss: 0.9043 - val_birthyear_out_mean_absolute_error: 0.1231 - val_fame_out_acc: 0.7421 - val_gender_out_acc: 0.8851 - val_occ_out_acc: 0.7063\n",
      "Epoch 2/30\n",
      "24354/24354 [==============================] - 21s 882us/step - loss: 2.2998 - birthyear_out_loss: 0.0276 - fame_out_loss: 0.6080 - gender_out_loss: 0.3221 - occ_out_loss: 0.8801 - birthyear_out_mean_absolute_error: 0.1300 - fame_out_acc: 0.7502 - gender_out_acc: 0.8654 - occ_out_acc: 0.7194 - val_loss: 2.1254 - val_birthyear_out_loss: 0.0244 - val_fame_out_loss: 0.5805 - val_gender_out_loss: 0.2500 - val_occ_out_loss: 0.8340 - val_birthyear_out_mean_absolute_error: 0.1196 - val_fame_out_acc: 0.7473 - val_gender_out_acc: 0.9080 - val_occ_out_acc: 0.7325\n",
      "Epoch 3/30\n",
      "24354/24354 [==============================] - 24s 1ms/step - loss: 2.0907 - birthyear_out_loss: 0.0266 - fame_out_loss: 0.5696 - gender_out_loss: 0.2652 - occ_out_loss: 0.8055 - birthyear_out_mean_absolute_error: 0.1273 - fame_out_acc: 0.7593 - gender_out_acc: 0.8912 - occ_out_acc: 0.7401 - val_loss: 2.0268 - val_birthyear_out_loss: 0.0244 - val_fame_out_loss: 0.5525 - val_gender_out_loss: 0.2311 - val_occ_out_loss: 0.7995 - val_birthyear_out_mean_absolute_error: 0.1208 - val_fame_out_acc: 0.7676 - val_gender_out_acc: 0.9069 - val_occ_out_acc: 0.7506\n",
      "Epoch 4/30\n",
      "24354/24354 [==============================] - 27s 1ms/step - loss: 1.9351 - birthyear_out_loss: 0.0259 - fame_out_loss: 0.5355 - gender_out_loss: 0.2376 - occ_out_loss: 0.7436 - birthyear_out_mean_absolute_error: 0.1251 - fame_out_acc: 0.7722 - gender_out_acc: 0.9029 - occ_out_acc: 0.7561 - val_loss: 2.0206 - val_birthyear_out_loss: 0.0239 - val_fame_out_loss: 0.5181 - val_gender_out_loss: 0.1964 - val_occ_out_loss: 0.8420 - val_birthyear_out_mean_absolute_error: 0.1170 - val_fame_out_acc: 0.7761 - val_gender_out_acc: 0.9265 - val_occ_out_acc: 0.7444\n",
      "Epoch 5/30\n",
      "24354/24354 [==============================] - 25s 1ms/step - loss: 1.8308 - birthyear_out_loss: 0.0258 - fame_out_loss: 0.5055 - gender_out_loss: 0.2092 - occ_out_loss: 0.7131 - birthyear_out_mean_absolute_error: 0.1250 - fame_out_acc: 0.7843 - gender_out_acc: 0.9158 - occ_out_acc: 0.7654 - val_loss: 1.9201 - val_birthyear_out_loss: 0.0243 - val_fame_out_loss: 0.4962 - val_gender_out_loss: 0.1841 - val_occ_out_loss: 0.7974 - val_birthyear_out_mean_absolute_error: 0.1194 - val_fame_out_acc: 0.7861 - val_gender_out_acc: 0.9287 - val_occ_out_acc: 0.7606\n",
      "Epoch 6/30\n",
      "24354/24354 [==============================] - 26s 1ms/step - loss: 1.6996 - birthyear_out_loss: 0.0251 - fame_out_loss: 0.4754 - gender_out_loss: 0.1884 - occ_out_loss: 0.6605 - birthyear_out_mean_absolute_error: 0.1235 - fame_out_acc: 0.7979 - gender_out_acc: 0.9253 - occ_out_acc: 0.7803 - val_loss: 1.9305 - val_birthyear_out_loss: 0.0237 - val_fame_out_loss: 0.4861 - val_gender_out_loss: 0.1848 - val_occ_out_loss: 0.8113 - val_birthyear_out_mean_absolute_error: 0.1149 - val_fame_out_acc: 0.7957 - val_gender_out_acc: 0.9287 - val_occ_out_acc: 0.7529hyear_out_loss: 0.0253 - fame_out_loss: 0.4738 - gender_out_loss: 0.1875 - occ_out_loss: 0 - ETA: 6s - loss: 1.7091 - birthyear_out_loss: 0.0252 - fame_out_loss: 0.4756 - gender_out_loss: 0.1898 - occ_out_loss: 0.6655 - birthyear_out_m\n",
      "Epoch 7/30\n",
      "24354/24354 [==============================] - 25s 1ms/step - loss: 1.6076 - birthyear_out_loss: 0.0251 - fame_out_loss: 0.4462 - gender_out_loss: 0.1756 - occ_out_loss: 0.6271 - birthyear_out_mean_absolute_error: 0.1233 - fame_out_acc: 0.8150 - gender_out_acc: 0.9313 - occ_out_acc: 0.7897 - val_loss: 1.9953 - val_birthyear_out_loss: 0.0238 - val_fame_out_loss: 0.5429 - val_gender_out_loss: 0.1950 - val_occ_out_loss: 0.8097 - val_birthyear_out_mean_absolute_error: 0.1155 - val_fame_out_acc: 0.7573 - val_gender_out_acc: 0.9257 - val_occ_out_acc: 0.7695ss: 0.6218 - birthyear_out_mean_absolute_error: 0.1233 - fame_out_acc: 0.8164\n",
      "Epoch 8/30\n",
      "24354/24354 [==============================] - 25s 1ms/step - loss: 1.5000 - birthyear_out_loss: 0.0245 - fame_out_loss: 0.4171 - gender_out_loss: 0.1579 - occ_out_loss: 0.5872 - birthyear_out_mean_absolute_error: 0.1215 - fame_out_acc: 0.8263 - gender_out_acc: 0.9381 - occ_out_acc: 0.8011 - val_loss: 1.8819 - val_birthyear_out_loss: 0.0235 - val_fame_out_loss: 0.4792 - val_gender_out_loss: 0.1690 - val_occ_out_loss: 0.7943 - val_birthyear_out_mean_absolute_error: 0.1150 - val_fame_out_acc: 0.7961 - val_gender_out_acc: 0.9361 - val_occ_out_acc: 0.7639\n",
      "Epoch 9/30\n",
      "24354/24354 [==============================] - 25s 1ms/step - loss: 1.4279 - birthyear_out_loss: 0.0247 - fame_out_loss: 0.3936 - gender_out_loss: 0.1491 - occ_out_loss: 0.5605 - birthyear_out_mean_absolute_error: 0.1223 - fame_out_acc: 0.8407 - gender_out_acc: 0.9417 - occ_out_acc: 0.8108 - val_loss: 1.9416 - val_birthyear_out_loss: 0.0236 - val_fame_out_loss: 0.4701 - val_gender_out_loss: 0.1764 - val_occ_out_loss: 0.8352 - val_birthyear_out_mean_absolute_error: 0.1168 - val_fame_out_acc: 0.8072 - val_gender_out_acc: 0.9342 - val_occ_out_acc: 0.7610\n",
      "Epoch 10/30\n",
      "24354/24354 [==============================] - 25s 1ms/step - loss: 1.3556 - birthyear_out_loss: 0.0245 - fame_out_loss: 0.3626 - gender_out_loss: 0.1451 - occ_out_loss: 0.5359 - birthyear_out_mean_absolute_error: 0.1214 - fame_out_acc: 0.8514 - gender_out_acc: 0.9456 - occ_out_acc: 0.8209 - val_loss: 1.9621 - val_birthyear_out_loss: 0.0242 - val_fame_out_loss: 0.4904 - val_gender_out_loss: 0.2020 - val_occ_out_loss: 0.8174 - val_birthyear_out_mean_absolute_error: 0.1180 - val_fame_out_acc: 0.8027 - val_gender_out_acc: 0.9254 - val_occ_out_acc: 0.7643\n",
      "Epoch 11/30\n",
      "24354/24354 [==============================] - 24s 999us/step - loss: 1.2940 - birthyear_out_loss: 0.0244 - fame_out_loss: 0.3429 - gender_out_loss: 0.1447 - occ_out_loss: 0.5083 - birthyear_out_mean_absolute_error: 0.1214 - fame_out_acc: 0.8614 - gender_out_acc: 0.9446 - occ_out_acc: 0.8313 - val_loss: 2.0073 - val_birthyear_out_loss: 0.0232 - val_fame_out_loss: 0.4872 - val_gender_out_loss: 0.1819 - val_occ_out_loss: 0.8644 - val_birthyear_out_mean_absolute_error: 0.1151 - val_fame_out_acc: 0.8079 - val_gender_out_acc: 0.9372 - val_occ_out_acc: 0.7625\n",
      "Epoch 12/30\n",
      "24354/24354 [==============================] - 26s 1ms/step - loss: 1.2205 - birthyear_out_loss: 0.0241 - fame_out_loss: 0.3263 - gender_out_loss: 0.1332 - occ_out_loss: 0.4784 - birthyear_out_mean_absolute_error: 0.1207 - fame_out_acc: 0.8704 - gender_out_acc: 0.9501 - occ_out_acc: 0.8388 - val_loss: 2.2130 - val_birthyear_out_loss: 0.0232 - val_fame_out_loss: 0.5135 - val_gender_out_loss: 0.1799 - val_occ_out_loss: 0.9852 - val_birthyear_out_mean_absolute_error: 0.1144 - val_fame_out_acc: 0.8024 - val_gender_out_acc: 0.9438 - val_occ_out_acc: 0.7536\n",
      "Epoch 13/30\n",
      "24354/24354 [==============================] - 24s 1ms/step - loss: 1.1503 - birthyear_out_loss: 0.0242 - fame_out_loss: 0.3063 - gender_out_loss: 0.1230 - occ_out_loss: 0.4516 - birthyear_out_mean_absolute_error: 0.1209 - fame_out_acc: 0.8785 - gender_out_acc: 0.9548 - occ_out_acc: 0.8486 - val_loss: 2.1155 - val_birthyear_out_loss: 0.0244 - val_fame_out_loss: 0.5031 - val_gender_out_loss: 0.2257 - val_occ_out_loss: 0.8952 - val_birthyear_out_mean_absolute_error: 0.1188 - val_fame_out_acc: 0.8027 - val_gender_out_acc: 0.9161 - val_occ_out_acc: 0.7669out_loss: 0.3067 - gender_out_loss: 0.1271 - occ_out_loss: 0.4542 - birthyear_out_mean_absolute_error: 0.1195 - fame_out_acc: 0.8774 - gen - ETA: 9s - loss: 1.1558 - birthyear_out_loss: 0.0238 - fame_out_loss: 0.3069 - gender_out\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24354/24354 [==============================] - 24s 1ms/step - loss: 1.1055 - birthyear_out_loss: 0.0239 - fame_out_loss: 0.2945 - gender_out_loss: 0.1186 - occ_out_loss: 0.4329 - birthyear_out_mean_absolute_error: 0.1198 - fame_out_acc: 0.8837 - gender_out_acc: 0.9559 - occ_out_acc: 0.8534 - val_loss: 2.0749 - val_birthyear_out_loss: 0.0247 - val_fame_out_loss: 0.5083 - val_gender_out_loss: 0.1845 - val_occ_out_loss: 0.8918 - val_birthyear_out_mean_absolute_error: 0.1201 - val_fame_out_acc: 0.8123 - val_gender_out_acc: 0.9328 - val_occ_out_acc: 0.7639ear_out_mean_absolute_error: 0.1194 - fame_out_acc: 0.8847 - gender_out_acc: 0.9574 - occ_out_acc: 0. - ETA: 8s - loss: 1.0941 - birthyear_out_loss: 0.0238 - fame_out_loss: 0.2960 - gender_out_loss: 0.1166 - occ_out_loss: 0.4257 - birthyear_out_mean_absolute_error: 0.1195 - fame_out_acc: 0.8847 - gender_out_acc: 0.9 - ETA: 6s - loss: 1.0955 - birthyear_out_loss: 0.0240 - fame_out_loss: 0.2953 - gender_out_loss: 0.1160 - occ_out_loss: 0.4273 - birthyear_out_mean_abso - ETA: 1s - loss: 1.1014 - birthyear_out_loss: 0.0238 - fame_out_loss: 0.2942 - gender_out_loss: 0.1191 - occ_out_loss: 0.4301 - birthyear_out_mean_absolute_error: 0.1197 - fame_out_acc: 0.8839 - gender_out_acc: 0.9559 - oc\n",
      "Epoch 15/30\n",
      "24354/24354 [==============================] - 25s 1ms/step - loss: 1.0580 - birthyear_out_loss: 0.0236 - fame_out_loss: 0.2791 - gender_out_loss: 0.1129 - occ_out_loss: 0.4158 - birthyear_out_mean_absolute_error: 0.1190 - fame_out_acc: 0.8902 - gender_out_acc: 0.9575 - occ_out_acc: 0.8600 - val_loss: 2.1154 - val_birthyear_out_loss: 0.0239 - val_fame_out_loss: 0.5168 - val_gender_out_loss: 0.1936 - val_occ_out_loss: 0.9080 - val_birthyear_out_mean_absolute_error: 0.1157 - val_fame_out_acc: 0.8064 - val_gender_out_acc: 0.9383 - val_occ_out_acc: 0.7676\n",
      "Epoch 16/30\n",
      "24354/24354 [==============================] - 25s 1ms/step - loss: 1.0099 - birthyear_out_loss: 0.0236 - fame_out_loss: 0.2690 - gender_out_loss: 0.1062 - occ_out_loss: 0.3948 - birthyear_out_mean_absolute_error: 0.1195 - fame_out_acc: 0.8944 - gender_out_acc: 0.9602 - occ_out_acc: 0.8676 - val_loss: 2.2355 - val_birthyear_out_loss: 0.0236 - val_fame_out_loss: 0.5443 - val_gender_out_loss: 0.1891 - val_occ_out_loss: 0.9731 - val_birthyear_out_mean_absolute_error: 0.1178 - val_fame_out_acc: 0.8131 - val_gender_out_acc: 0.9383 - val_occ_out_acc: 0.77130.3965 - birthyear_out_mean_absolute_error: 0.1194 - fame_\n",
      "Epoch 17/30\n",
      "24354/24354 [==============================] - 26s 1ms/step - loss: 0.9622 - birthyear_out_loss: 0.0237 - fame_out_loss: 0.2451 - gender_out_loss: 0.1066 - occ_out_loss: 0.3785 - birthyear_out_mean_absolute_error: 0.1196 - fame_out_acc: 0.9032 - gender_out_acc: 0.9599 - occ_out_acc: 0.8744 - val_loss: 2.2565 - val_birthyear_out_loss: 0.0228 - val_fame_out_loss: 0.5592 - val_gender_out_loss: 0.1899 - val_occ_out_loss: 0.9776 - val_birthyear_out_mean_absolute_error: 0.1136 - val_fame_out_acc: 0.8157 - val_gender_out_acc: 0.9431 - val_occ_out_acc: 0.7525ETA: 8s - loss: 0.9459 - birthyear_out_loss: 0.0233 - fame_out_loss: 0.2450 - gender_out_loss: 0.1051 \n",
      "Epoch 18/30\n",
      "24354/24354 [==============================] - 26s 1ms/step - loss: 0.9424 - birthyear_out_loss: 0.0234 - fame_out_loss: 0.2504 - gender_out_loss: 0.1022 - occ_out_loss: 0.3652 - birthyear_out_mean_absolute_error: 0.1185 - fame_out_acc: 0.9035 - gender_out_acc: 0.9623 - occ_out_acc: 0.8768 - val_loss: 2.1761 - val_birthyear_out_loss: 0.0238 - val_fame_out_loss: 0.5170 - val_gender_out_loss: 0.1775 - val_occ_out_loss: 0.9591 - val_birthyear_out_mean_absolute_error: 0.1190 - val_fame_out_acc: 0.8090 - val_gender_out_acc: 0.9431 - val_occ_out_acc: 0.7540- fame_out_acc: 0.90 - ETA: 1s - loss: 0.9426 - birthyear_out_loss: 0.0232 - fame_out_loss: 0.2507 - gender_out_loss: 0.1021 - occ_out_loss: 0.3653 - birthyear_out_mean_absolute_error: 0.1181 - fame_out_acc: 0.9032 - gender_out_acc: 0.9\n",
      "Epoch 19/30\n",
      "24354/24354 [==============================] - 26s 1ms/step - loss: 0.9400 - birthyear_out_loss: 0.0236 - fame_out_loss: 0.2444 - gender_out_loss: 0.1057 - occ_out_loss: 0.3650 - birthyear_out_mean_absolute_error: 0.1193 - fame_out_acc: 0.9063 - gender_out_acc: 0.9605 - occ_out_acc: 0.8762 - val_loss: 2.2414 - val_birthyear_out_loss: 0.0230 - val_fame_out_loss: 0.4952 - val_gender_out_loss: 0.1869 - val_occ_out_loss: 1.0120 - val_birthyear_out_mean_absolute_error: 0.1140 - val_fame_out_acc: 0.8079 - val_gender_out_acc: 0.9427 - val_occ_out_acc: 0.762536 - gender_out_loss: 0.1058 - occ_out_loss: 0.3656 - birthyear_out_mean_absolute_error: 0.1195 - fame_o\n",
      "Epoch 20/30\n",
      "24354/24354 [==============================] - 25s 1ms/step - loss: 0.8760 - birthyear_out_loss: 0.0235 - fame_out_loss: 0.2256 - gender_out_loss: 0.0957 - occ_out_loss: 0.3416 - birthyear_out_mean_absolute_error: 0.1184 - fame_out_acc: 0.9127 - gender_out_acc: 0.9650 - occ_out_acc: 0.8864 - val_loss: 2.2326 - val_birthyear_out_loss: 0.0237 - val_fame_out_loss: 0.5414 - val_gender_out_loss: 0.1910 - val_occ_out_loss: 0.9716 - val_birthyear_out_mean_absolute_error: 0.1145 - val_fame_out_acc: 0.8101 - val_gender_out_acc: 0.9461 - val_occ_out_acc: 0.7647: 0.2251 - gender_out_loss: 0.0965 - occ_out_loss: 0.3401 - birthyear_out_mean_absolute_error: 0.1183 - fame_out_acc: 0.9130 - gender_out_acc: 0\n",
      "Epoch 21/30\n",
      "24354/24354 [==============================] - 26s 1ms/step - loss: 0.8434 - birthyear_out_loss: 0.0231 - fame_out_loss: 0.2158 - gender_out_loss: 0.0924 - occ_out_loss: 0.3292 - birthyear_out_mean_absolute_error: 0.1175 - fame_out_acc: 0.9179 - gender_out_acc: 0.9646 - occ_out_acc: 0.8896 - val_loss: 2.2962 - val_birthyear_out_loss: 0.0231 - val_fame_out_loss: 0.5525 - val_gender_out_loss: 0.1817 - val_occ_out_loss: 1.0136 - val_birthyear_out_mean_absolute_error: 0.1160 - val_fame_out_acc: 0.8035 - val_gender_out_acc: 0.9464 - val_occ_out_acc: 0.7639\n",
      "Epoch 22/30\n",
      "24354/24354 [==============================] - 25s 1ms/step - loss: 0.8123 - birthyear_out_loss: 0.0231 - fame_out_loss: 0.2023 - gender_out_loss: 0.0876 - occ_out_loss: 0.3206 - birthyear_out_mean_absolute_error: 0.1177 - fame_out_acc: 0.9211 - gender_out_acc: 0.9683 - occ_out_acc: 0.8900 - val_loss: 2.4365 - val_birthyear_out_loss: 0.0236 - val_fame_out_loss: 0.6007 - val_gender_out_loss: 0.1717 - val_occ_out_loss: 1.0810 - val_birthyear_out_mean_absolute_error: 0.1159 - val_fame_out_acc: 0.8079 - val_gender_out_acc: 0.9398 - val_occ_out_acc: 0.7643\n",
      "Epoch 23/30\n",
      "24354/24354 [==============================] - 25s 1ms/step - loss: 0.8033 - birthyear_out_loss: 0.0232 - fame_out_loss: 0.2078 - gender_out_loss: 0.0899 - occ_out_loss: 0.3092 - birthyear_out_mean_absolute_error: 0.1178 - fame_out_acc: 0.9219 - gender_out_acc: 0.9683 - occ_out_acc: 0.8971 - val_loss: 2.6275 - val_birthyear_out_loss: 0.0236 - val_fame_out_loss: 0.5532 - val_gender_out_loss: 0.2204 - val_occ_out_loss: 1.2076 - val_birthyear_out_mean_absolute_error: 0.1151 - val_fame_out_acc: 0.8064 - val_gender_out_acc: 0.9250 - val_occ_out_acc: 0.7721ss: 0.0234 - fame_out_loss: 0.2074 - gender_out_loss: 0.0878 - occ_out_loss: 0.3103 - birthye - ETA: 9s - loss: 0.7976 - birthyear_out_loss: 0.0233 - fame_out_loss: 0.2048 - gen\n",
      "Epoch 24/30\n",
      "24354/24354 [==============================] - 26s 1ms/step - loss: 0.7666 - birthyear_out_loss: 0.0228 - fame_out_loss: 0.2009 - gender_out_loss: 0.0861 - occ_out_loss: 0.2924 - birthyear_out_mean_absolute_error: 0.1170 - fame_out_acc: 0.9228 - gender_out_acc: 0.9683 - occ_out_acc: 0.9001 - val_loss: 2.5920 - val_birthyear_out_loss: 0.0243 - val_fame_out_loss: 0.5962 - val_gender_out_loss: 0.1805 - val_occ_out_loss: 1.1811 - val_birthyear_out_mean_absolute_error: 0.1149 - val_fame_out_acc: 0.8098 - val_gender_out_acc: 0.9453 - val_occ_out_acc: 0.7647\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24354/24354 [==============================] - 24s 973us/step - loss: 0.7583 - birthyear_out_loss: 0.0231 - fame_out_loss: 0.1950 - gender_out_loss: 0.0814 - occ_out_loss: 0.2936 - birthyear_out_mean_absolute_error: 0.1175 - fame_out_acc: 0.9242 - gender_out_acc: 0.9694 - occ_out_acc: 0.9005 - val_loss: 2.7036 - val_birthyear_out_loss: 0.0260 - val_fame_out_loss: 0.6083 - val_gender_out_loss: 0.2293 - val_occ_out_loss: 1.2128 - val_birthyear_out_mean_absolute_error: 0.1200 - val_fame_out_acc: 0.8127 - val_gender_out_acc: 0.9472 - val_occ_out_acc: 0.7680\n",
      "Epoch 26/30\n",
      "24354/24354 [==============================] - 26s 1ms/step - loss: 0.7497 - birthyear_out_loss: 0.0228 - fame_out_loss: 0.1927 - gender_out_loss: 0.0839 - occ_out_loss: 0.2881 - birthyear_out_mean_absolute_error: 0.1167 - fame_out_acc: 0.9261 - gender_out_acc: 0.9691 - occ_out_acc: 0.9031 - val_loss: 2.4462 - val_birthyear_out_loss: 0.0238 - val_fame_out_loss: 0.6120 - val_gender_out_loss: 0.1949 - val_occ_out_loss: 1.0643 - val_birthyear_out_mean_absolute_error: 0.1166 - val_fame_out_acc: 0.8035 - val_gender_out_acc: 0.9405 - val_occ_out_acc: 0.76140.1925 - gender_out_loss: 0.0842 - occ_out_loss: 0.2866 - birthyear_out_mean_absolute_error: 0.1164 - fame_out_acc: 0.9259 - gender_out_acc: 0.9693 -  - ETA: 0s - loss: 0.7497 - birthyear_out_loss: 0.0227 - fame_out_loss: 0.1929 - gender_out_loss: 0.0838 - occ_out_loss: 0.2880 - birthyear_out_mean_absolute_error: 0.1167 - fame_out_acc: 0.9260 - gender_out_acc: 0.9691 - occ_out_acc: 0.9\n",
      "Epoch 27/30\n",
      "24354/24354 [==============================] - 25s 1ms/step - loss: 0.7245 - birthyear_out_loss: 0.0228 - fame_out_loss: 0.1823 - gender_out_loss: 0.0810 - occ_out_loss: 0.2801 - birthyear_out_mean_absolute_error: 0.1170 - fame_out_acc: 0.9309 - gender_out_acc: 0.9701 - occ_out_acc: 0.9059 - val_loss: 2.6153 - val_birthyear_out_loss: 0.0245 - val_fame_out_loss: 0.6480 - val_gender_out_loss: 0.2048 - val_occ_out_loss: 1.1456 - val_birthyear_out_mean_absolute_error: 0.1212 - val_fame_out_acc: 0.7998 - val_gender_out_acc: 0.9413 - val_occ_out_acc: 0.7506\n",
      "Epoch 28/30\n",
      "24354/24354 [==============================] - 25s 1ms/step - loss: 0.7243 - birthyear_out_loss: 0.0223 - fame_out_loss: 0.1851 - gender_out_loss: 0.0797 - occ_out_loss: 0.2796 - birthyear_out_mean_absolute_error: 0.1152 - fame_out_acc: 0.9297 - gender_out_acc: 0.9704 - occ_out_acc: 0.9086 - val_loss: 2.5704 - val_birthyear_out_loss: 0.0234 - val_fame_out_loss: 0.6034 - val_gender_out_loss: 0.1841 - val_occ_out_loss: 1.1605 - val_birthyear_out_mean_absolute_error: 0.1167 - val_fame_out_acc: 0.8086 - val_gender_out_acc: 0.9409 - val_occ_out_acc: 0.7687\n",
      "Epoch 29/30\n",
      "24354/24354 [==============================] - 26s 1ms/step - loss: 0.6980 - birthyear_out_loss: 0.0224 - fame_out_loss: 0.1806 - gender_out_loss: 0.0753 - occ_out_loss: 0.2678 - birthyear_out_mean_absolute_error: 0.1154 - fame_out_acc: 0.9324 - gender_out_acc: 0.9729 - occ_out_acc: 0.9110 - val_loss: 2.6605 - val_birthyear_out_loss: 0.0229 - val_fame_out_loss: 0.6712 - val_gender_out_loss: 0.2145 - val_occ_out_loss: 1.1557 - val_birthyear_out_mean_absolute_error: 0.1128 - val_fame_out_acc: 0.8042 - val_gender_out_acc: 0.9394 - val_occ_out_acc: 0.7628\n",
      "Epoch 30/30\n",
      "24354/24354 [==============================] - 25s 1ms/step - loss: 0.6939 - birthyear_out_loss: 0.0223 - fame_out_loss: 0.1821 - gender_out_loss: 0.0764 - occ_out_loss: 0.2634 - birthyear_out_mean_absolute_error: 0.1151 - fame_out_acc: 0.9327 - gender_out_acc: 0.9740 - occ_out_acc: 0.9129 - val_loss: 2.8287 - val_birthyear_out_loss: 0.0235 - val_fame_out_loss: 0.6757 - val_gender_out_loss: 0.2114 - val_occ_out_loss: 1.2663 - val_birthyear_out_mean_absolute_error: 0.1179 - val_fame_out_acc: 0.7998 - val_gender_out_acc: 0.9390 - val_occ_out_acc: 0.7662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2240c228be0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = [birthyear_train, fame_train, gender_train, occ_train]\n",
    "start_epoch = 0\n",
    "end_epoch = 30\n",
    "bs = 32\n",
    "split_fac = 0.1\n",
    "callbacks = [board, chkpt]\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=end_epoch,\n",
    "          batch_size=bs,\n",
    "          callbacks=callbacks,\n",
    "          initial_epoch=start_epoch,\n",
    "          validation_split=split_fac,\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = None\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"model-30epochs-60dropout-final.h5\"\n",
    "#model.save('model/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\model-35epochs-60dropout.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-d01708b20d08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'C:\\Users\\Tollef\\Desktop\\Spring2019\\TextAnalysis\\project\\PAN-celebrity-profiling\\data\\model-35epochs-60dropout.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(os.getcwd(), model_name)\n",
    "model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6765/6765 [==============================] - 2s 283us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8442904035338454,\n",
       " 0.024066422071310652,\n",
       " 0.48857188614227115,\n",
       " 0.18288909037379275,\n",
       " 0.7530065819059402,\n",
       " 0.11878173513295293,\n",
       " 0.7992609017175476,\n",
       " 0.9315594974219666,\n",
       " 0.7739837398550199]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(x_val, [birthyear_val, fame_val, gender_val, occ_val])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "_min = 1940\n",
    "_max = 2008\n",
    "def predict_user(model, user_vec, actual=None, verbose=False):\n",
    "    result = model.predict([[user_vec]])\n",
    "    fame = [\"rising\", \"star\", \"superstar\"]\n",
    "    gender = [\"female\", \"male\", \"nonbinary\"]\n",
    "    occupation = [\"creator\", \"manager\", \"performer\", \"politics\", \"professional\", \"religious\", \"science\", \"sports\"]\n",
    "\n",
    "    birth_pred = result[0][0][0]\n",
    "    fame_pred = result[1][0]\n",
    "    gender_pred = result[2][0]\n",
    "    occ_pred = result[3][0]\n",
    "    \n",
    "    errors = False  # check for errors on the fame/gender/occupation metrics\n",
    "    \n",
    "    year_pred = int(birth_pred * (_max - _min) + _min)\n",
    "    year_real = int(birthyear_val[actual] * (_max - _min) + _min)\n",
    "    \n",
    "    fame_pred = fame[fame_pred.argmax()]\n",
    "    fame_real = fame_val.iloc[actual].idxmax()\n",
    "    \n",
    "    gend_pred = gender[gender_pred.argmax()]\n",
    "    gend_real = gender_val.iloc[actual].idxmax()\n",
    "    \n",
    "    occu_pred = occupation[occ_pred.argmax()]\n",
    "    occu_real = occ_val.iloc[actual].idxmax()\n",
    "    \n",
    "    errors = [fame_pred != fame_real, gend_pred != gend_real, occu_pred != occu_real]\n",
    "\n",
    "    if verbose and sum(errors) != 0:  # only print wrong predictions!\n",
    "        #print(\"Predicted values (real ones in parentheses)\")\n",
    "        print('Birthyear:\\t{} ({})'.format(year_pred, year_real))\n",
    "        print('Fame status:\\t{} ({})'.format(fame_pred, fame_real))\n",
    "        print('Gender:   \\t{} ({})'.format(gend_pred, gend_real))\n",
    "        print('Occupation:\\t{} ({})'.format(occu_pred, occu_real))\n",
    "        # print some of the text...\n",
    "        print(\"--------------------------------------------\")\n",
    "        \n",
    "    return abs(year_pred - year_real), errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average off by 8.034 years\n",
      "Fame err: 202/1000\n",
      "Gender err: 70/1000\n",
      "Occupation err: 241/1000\n"
     ]
    }
   ],
   "source": [
    "birthyear_errors = []\n",
    "errors = {'fame': 0, 'gender': 0, 'occupation': 0}\n",
    "# test_size\n",
    "tests = 1000\n",
    "for i in range(tests):\n",
    "    year_diff, error = predict_user(model, x_val[i], actual=i, verbose=False)\n",
    "    birthyear_errors.append(year_diff)\n",
    "    errors['fame'] += error[0]\n",
    "    errors['gender'] += error[1]\n",
    "    errors['occupation'] += error[2]\n",
    "    \n",
    "    \n",
    "print('Average off by {} years'.format(sum(birthyear_errors)/len(birthyear_errors)))\n",
    "print('Fame err: {}/{}'.format(errors['fame'], tests))\n",
    "print('Gender err: {}/{}'.format(errors['gender'], tests))\n",
    "print('Occupation err: {}/{}'.format(errors['occupation'], tests))\n",
    "\n",
    "# create object with which labels were misclassified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
