{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split as SPLIT\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined_cleaned.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64705882, 0.30882353, 0.72058824, ..., 0.45588235, 0.73529412,\n",
       "       0.58823529])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify birthyear-> 0-1 on a float scale\n",
    "birthyears = df.birthyear.unique()\n",
    "_min = min(birthyears)\n",
    "_max = max(birthyears)\n",
    "\n",
    "def normalize_birthyear(year):\n",
    "    return (year-_min)/(_max-_min)\n",
    "\n",
    "birthyear_labels = df.birthyear.apply(normalize_birthyear)\n",
    "birthyear_labels = birthyear_labels.values\n",
    "birthyear_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 unique classes in fame\n",
      "3 unique classes in gender\n",
      "8 unique classes in occupation\n"
     ]
    }
   ],
   "source": [
    "labels_to_onehot = ['fame', 'gender', 'occupation']\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "labels = {}\n",
    "\n",
    "for label in labels_to_onehot:\n",
    "    unique_classes = len(df[label].unique())\n",
    "    print('{} unique classes in {}'.format(unique_classes, label))\n",
    "    labels_nd = df[label].values\n",
    "    labels[label] = labels_nd\n",
    "    #encoder = LabelBinarizer()\n",
    "    #labels[label] = encoder.fit_transform(labels_nd)\n",
    "    labels[label] = pd.get_dummies(labels_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fame_labels = labels['fame']\n",
    "gender_labels = labels['gender']\n",
    "occ_labels = labels['occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6996, 2)\n",
      "(6996, 3)\n",
      "(6996, 8)\n"
     ]
    }
   ],
   "source": [
    "#fame_labels = to_categorical(fame_labels)\n",
    "#gender_labels = to_categorical(gender_labels)\n",
    "#occ_labels = to_categorical(occ_labels)\n",
    "\n",
    "print(fame_labels.shape)\n",
    "print(gender_labels.shape)\n",
    "print(occ_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "vocab_size = 15000\n",
    " \n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(df.text)\n",
    " \n",
    "x_train = tokenizer.texts_to_matrix(df.text, mode='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# loading\n",
    "#with open('tokenizer.pickle', 'rb') as handle:\n",
    "#    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "fame_labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 15000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 128)          1920128     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 128)          16512       dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 128)          16512       dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 128)          16512       dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 128)          16512       dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "birthyear_out (Dense)           (None, 1)            129         dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fame_out (Dense)                (None, 2)            258         dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gender_out (Dense)              (None, 3)            387         dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "occ_out (Dense)                 (None, 8)            1032        dense_28[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,987,982\n",
      "Trainable params: 1,987,982\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tollef\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "shape = (vocab_size,)\n",
    "input_layer = Input(shape)\n",
    "# before splitting categories\n",
    "branch_layer = Dense(units=128, activation='relu')(input_layer)\n",
    "# birthyear\n",
    "_ = Dense(units=128, activation='relu')(branch_layer)\n",
    "birthyear_out = Dense(units=1, activation='sigmoid', name='birthyear_out')(_)\n",
    "\n",
    "# fame\n",
    "_ = Dense(units=128, activation='relu')(branch_layer)\n",
    "fame_out = Dense(units=fame_labels.shape[1], activation='softmax', name='fame_out')(_)\n",
    "\n",
    "# gender\n",
    "_ = Dense(units=128, activation='relu')(branch_layer)\n",
    "gender_out = Dense(units=gender_labels.shape[1], activation='softmax', name='gender_out')(_)\n",
    "\n",
    "# occupation\n",
    "_ = Dense(units=128, activation='relu')(branch_layer)\n",
    "occ_out = Dense(units=occ_labels.shape[1], activation='softmax', name='occ_out')(_)\n",
    "\n",
    "model = Model(input=input_layer, outputs=[birthyear_out, fame_out, gender_out, occ_out])\n",
    "#model = Model(input=input_layer, outputs=fame_out)\n",
    "loss_fn = 'categorical_crossentropy'\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'birthyear_out': 'mse', 'fame_out': loss_fn, 'gender_out': loss_fn, 'occ_out': loss_fn},\n",
    "              metrics={'birthyear_out': 'mae', 'fame_out': 'accuracy', 'gender_out': 'accuracy', 'occ_out': 'accuracy'}\n",
    "             )\n",
    "\n",
    "#model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tollef\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      " 416/6996 [>.............................] - ETA: 33s - loss: 3905906.8846 - birthyear_out_loss: 3905900.2115 - fame_out_loss: 1.3021 - gender_out_loss: 1.8349 - occ_out_loss: 3.5745 - birthyear_out_mean_absolute_error: 1976.2872 - fame_out_acc: 0.5673 - gender_out_acc: 0.6034 - occ_out_acc: 0.3678"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, [df.birthyear.values, fame_labels, gender_labels, occ_labels], epochs=2, batch_size=32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, _fame, epochs=2, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
